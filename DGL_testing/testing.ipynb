{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/victoria/Documents/Scripts/Python/DGL-PTM/dgl_ptm')\n",
    "import dgl_ptm\n",
    "import os\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dgl_ptm.PovertyTrapModel(model_identifier='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'npath': './agent_data.zarr', 'epath': './edge_data', 'ndata': ['all_except', ['a_table']], 'edata': ['all'], 'mode': 'xarray', 'wealth_method': 'singular_transfer', 'income_method': 'pseudo_income_generation', 'tech_gamma': tensor([0.3000, 0.3500, 0.4500]), 'tech_cost': tensor([0.0000, 0.1500, 0.6500]), 'consume_method': 'pseudo_consumption', 'adapt_m': tensor([0.0000, 0.5000, 0.9000]), 'adapt_cost': tensor([0.0000, 0.2500, 0.4500]), 'depreciation': 0.6, 'discount': 0.95, 'm_theta_dist': {'type': 'multinomial', 'parameters': [[0.01, 0.1, 0.79, 0.1], [0.1, 0.5, 0.8, 1]], 'round': False, 'decimals': None}, 'del_prob': 0.05, 'ratio': 0.1, 'weight_a': 0.69, 'weight_b': 35, 'truncation_weight': 1e-10, 'step_type': 'default'}\n"
     ]
    }
   ],
   "source": [
    "model.set_model_parameters(default=True)\n",
    "print(model.steering_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing step 1 of 20\n",
      "dst node 92 is an end node\n",
      "no FoF link possible for src dst nodes 0 and 92.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 2 of 20\n",
      "creating bidirectional link between nodes 91 (src) and tensor([8]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 3 of 20\n",
      "creating bidirectional link between nodes 80 (src) and tensor([59]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 4 of 20\n",
      "creating bidirectional link between nodes 52 (src) and tensor([66]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 5 of 20\n",
      "dst node 50 is an end node\n",
      "no FoF link possible for src dst nodes 29 and 50.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 6 of 20\n",
      "creating bidirectional link between nodes 44 (src) and tensor([0]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 7 of 20\n",
      "creating bidirectional link between nodes 18 (src) and tensor([79]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 8 of 20\n",
      "all FoF nodes are already direcctly connected to node 79.\n",
      "no FoF link possible for src dst nodes 79 and 35.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 9 of 20\n",
      "creating bidirectional link between nodes 81 (src) and tensor([24]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 10 of 20\n",
      "dst node 17 is an end node\n",
      "no FoF link possible for src dst nodes 25 and 17.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 11 of 20\n",
      "creating bidirectional link between nodes 34 (src) and tensor([8]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 12 of 20\n",
      "all FoF nodes are already direcctly connected to node 19.\n",
      "no FoF link possible for src dst nodes 19 and 34.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 13 of 20\n",
      "creating bidirectional link between nodes 0 (src) and tensor([3]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 14 of 20\n",
      "dst node 55 is an end node\n",
      "no FoF link possible for src dst nodes 11 and 55.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 15 of 20\n",
      "creating bidirectional link between nodes 5 (src) and tensor([2]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 16 of 20\n",
      "dst node 57 is an end node\n",
      "no FoF link possible for src dst nodes 45 and 57.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 17 of 20\n",
      "creating bidirectional link between nodes 79 (src) and tensor([7]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 18 of 20\n",
      "dst node 49 is an end node\n",
      "no FoF link possible for src dst nodes 52 and 49.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 19 of 20\n",
      "dst node 55 is an end node\n",
      "no FoF link possible for src dst nodes 11 and 55.\n",
      "created 0 of 1 links requested\n",
      "gets to data collection\n",
      "performing step 20 of 20\n",
      "creating bidirectional link between nodes 63 (src) and tensor([93]) (dst)\n",
      "created 1 of 1 links requested\n",
      "gets to data collection\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dgl_ptm.PovertyTrapModel(model_identifier='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'npath': './agent_data.zarr', 'epath': './edge_data', 'ndata': ['all_except', ['a_table']], 'edata': ['all'], 'mode': 'xarray', 'wealth_method': 'singular_transfer', 'income_method': 'income_generation', 'tech_gamma': tensor([0.3000, 0.3500, 0.4500]), 'tech_cost': tensor([0.0000, 0.1500, 0.6500]), 'consume_method': 'optimized_consumption', 'adapt_m': tensor([0.0000, 0.5000, 0.9000]), 'adapt_cost': tensor([0.0000, 0.2500, 0.4500]), 'depreciation': 0.6, 'discount': 0.95, 'm_theta_dist': {'type': 'multinomial', 'parameters': [[0.01, 0.1, 0.79, 0.1], [0.1, 0.5, 0.8, 1]], 'round': False, 'decimals': None}, 'del_prob': 0.05, 'ratio': 0.1, 'weight_a': 0.69, 'weight_b': 35, 'truncation_weight': 1e-10, 'step_type': 'custom'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model.set_model_parameters(default=False, **{'steering_parameters': {'npath':'./agent_data.zarr',\n",
    "                            'epath':'./edge_data', \n",
    "                            'ndata':['all_except',['a_table']],\n",
    "                            'edata':['all'],\n",
    "                            'mode':'xarray',\n",
    "                            'wealth_method':'singular_transfer',\n",
    "                            'income_method':'income_generation',\n",
    "                            'tech_gamma': torch.tensor([0.3,0.35,0.45]),\n",
    "                            'tech_cost': torch.tensor([0,0.15,0.65]),\n",
    "                            'consume_method':'optimized_consumption',\n",
    "                            'adapt_m':torch.tensor([0,0.5,0.9]),\n",
    "                            'adapt_cost':torch.tensor([0,0.25,0.45]),\n",
    "                            'depreciation': 0.6,\n",
    "                            'discount': 0.95,\n",
    "                            'm_theta_dist': {'type':'multinomial','parameters':[[0.01 ,0.1, 0.79, 0.1],[0.1, 0.5, 0.8, 1]],'round':False,'decimals':None},\n",
    "                            'del_prob':0.05,\n",
    "                            'ratio':0.1,\n",
    "                            'weight_a':0.69,\n",
    "                            'weight_b':35, \n",
    "                            'truncation_weight':1.0e-10,\n",
    "                            'step_type': 'custom'}})\n",
    "\n",
    "print(model.number_agents)  \n",
    "print(model.steering_parameters)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing step 1 of 20\n",
      "dst node 91 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 91.\n",
      "created 0 of 1 links requested\n",
      "tensor([3.2029e+00, 5.9491e-01, 8.2273e-01, 3.9132e-03, 9.7171e-01, 3.2698e+00,\n",
      "        5.4570e-01, 3.8353e+00, 1.3132e-03, 9.0159e-01, 1.5566e-01, 1.5950e+00,\n",
      "        4.0562e+00, 1.1643e+00, 6.7009e-04, 9.0837e-01, 1.0512e+00, 2.4808e+00,\n",
      "        1.3334e+00, 5.9333e+00, 1.9972e+00, 2.9975e-01, 7.8517e-01, 1.5069e+00,\n",
      "        2.2790e-01, 6.8250e-02, 3.7630e+00, 2.7318e+00, 2.1619e+00, 8.2732e-01,\n",
      "        6.4566e-01, 2.7197e+00, 5.3587e+00, 3.1591e-02, 1.0662e+00, 3.7420e+00,\n",
      "        3.3982e+00, 7.6127e-02, 3.0553e+00, 2.4880e+00, 2.4515e+00, 4.0384e+00,\n",
      "        7.7789e-01, 3.0177e+00, 1.7469e+00, 1.7339e+00, 8.2605e-04, 2.5885e+00,\n",
      "        8.8006e-01, 3.4454e-02, 2.3518e+00, 1.4662e-01, 1.2753e+00, 3.8384e+00,\n",
      "        2.0337e+00, 1.1884e-02, 2.9275e-03, 5.9572e-01, 2.3796e-01, 3.2560e+00,\n",
      "        5.3400e-03, 1.3972e+00, 2.3045e+00, 7.1039e-01, 2.9268e+00, 4.8140e+00,\n",
      "        9.6590e-01, 8.2451e-03, 9.1404e-04, 1.5566e+00, 1.4979e+00, 3.8192e-03,\n",
      "        1.8307e-01, 2.1505e-01, 2.3707e-01, 6.6067e-01, 8.0323e-02, 4.2293e-01,\n",
      "        2.9910e-03, 2.4511e+00, 1.0285e+00, 1.0686e+00, 5.5288e-02, 2.0184e-01,\n",
      "        1.7485e+00, 1.5750e+00, 3.0687e+00, 7.0214e-01, 2.5373e+00, 2.7719e-02,\n",
      "        1.4573e-03, 1.2514e+00, 2.7622e-03, 2.6988e-01, 4.6243e+00, 2.1340e+00,\n",
      "        5.6483e-01, 3.4298e-01, 1.4157e+00, 2.4534e+00])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "        0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000,\n",
      "        0.0000])\n",
      "gets to data collection\n",
      "performing step 2 of 20\n",
      "creating bidirectional link between nodes 87 (src) and tensor([33]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([9.3245e-01, 3.6868e-01, 5.1741e-01, 1.9894e-01, 7.5014e-01, 3.1314e-01,\n",
      "        3.2839e-01, 8.2298e-01, 1.8580e-03, 4.2234e-01, 1.7151e-01, 4.6073e-01,\n",
      "        5.9782e-01, 1.7159e-01, 4.9992e-01, 6.7303e-01, 7.0625e-01, 8.0173e-01,\n",
      "        6.9596e-01, 4.5167e+01, 9.5395e-01, 5.2717e-01, 6.9874e-01, 9.7844e-01,\n",
      "        6.7501e-01, 1.2892e-02, 4.5793e+01, 1.0268e+00, 4.0580e-01, 5.8884e-01,\n",
      "        2.7454e-01, 9.0245e-01, 7.0050e-01, 2.3319e-01, 6.4863e-01, 8.9950e-01,\n",
      "        1.5181e+00, 4.4753e-02, 1.0237e+00, 1.1268e+00, 9.3490e-01, 9.0509e-01,\n",
      "        4.4853e-01, 9.5875e-01, 3.4993e-01, 1.0774e+00, 3.6406e-04, 9.5169e-01,\n",
      "        2.6767e-01, 2.9817e-02, 5.5745e-01, 1.1736e-01, 5.4811e-01, 2.9613e-01,\n",
      "        1.4650e+00, 7.3246e-03, 2.7177e-01, 4.4169e-01, 2.4019e-01, 1.2823e+00,\n",
      "        5.1785e-03, 5.1454e-01, 2.1450e-01, 3.6639e-02, 3.2705e-01, 6.0540e-01,\n",
      "        6.4147e-01, 5.5713e-03, 4.3881e-04, 7.2497e-01, 7.7655e-01, 3.3577e-03,\n",
      "        8.1606e-02, 3.1435e-01, 1.4807e-01, 6.5313e-01, 6.2303e-02, 3.3109e-01,\n",
      "        1.1328e-03, 4.4433e+01, 8.4369e-01, 2.5602e-01, 1.4759e-01, 1.3667e-01,\n",
      "        8.8216e-01, 7.2349e-01, 7.7432e-01, 7.7174e-01, 8.6203e-01, 2.2662e-01,\n",
      "        2.9756e-03, 9.4937e-01, 2.2962e-03, 1.7037e-01, 6.2543e-01, 8.4951e-01,\n",
      "        6.9485e-01, 7.4784e-01, 1.0666e+00, 2.4099e-01])\n",
      "tensor([0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000,\n",
      "        0.0000, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.2500, 0.4500, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000,\n",
      "        0.0000, 0.0000, 0.2500, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "        0.0000])\n",
      "tensor([0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.5000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.5000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.9000,\n",
      "        0.0000])\n",
      "gets to data collection\n",
      "performing step 3 of 20\n",
      "creating bidirectional link between nodes 69 (src) and tensor([96]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([6.6353e-02, 4.7601e-02, 2.5382e-01, 7.2187e-04, 1.8392e-03, 1.3013e-01,\n",
      "        1.9995e-01, 1.8087e-01, 5.7832e-04, 1.6414e-03, 1.8756e-01, 2.1027e-01,\n",
      "        1.3358e-01, 1.9267e-01, 1.2119e-04, 2.3267e-01, 6.6782e-04, 1.5081e-01,\n",
      "        4.0249e-03, 4.9497e+00, 6.2877e-02, 4.4171e-04, 1.1755e-02, 8.1877e-04,\n",
      "        1.1631e-04, 7.3600e-03, 8.1455e+00, 1.4826e-01, 1.2753e-01, 1.1115e-01,\n",
      "        1.6568e-01, 1.8326e-01, 2.8080e-02, 2.3700e-02, 9.4422e-03, 8.3915e-02,\n",
      "        1.1649e-01, 5.6350e-02, 4.7044e-02, 1.5380e-01, 1.5345e-02, 2.1895e-02,\n",
      "        3.0092e-01, 1.7867e-01, 9.7408e-02, 1.1404e-01, 3.6315e-04, 1.5253e-01,\n",
      "        2.0595e-01, 2.8310e-02, 8.6867e-04, 1.2526e-01, 1.1489e-01, 1.9549e-01,\n",
      "        5.9264e-01, 2.7501e-03, 4.3967e-04, 1.4740e-01, 1.9561e-01, 1.6581e-01,\n",
      "        2.1247e-03, 1.9272e-01, 1.1647e-01, 1.4573e-01, 7.0259e-02, 1.9519e-01,\n",
      "        2.6722e-04, 3.5410e-03, 4.3035e-04, 3.8765e-03, 1.5161e-02, 1.2005e-03,\n",
      "        7.8434e-02, 4.1800e-02, 3.4256e-01, 7.6938e-02, 1.8369e-02, 2.3029e-02,\n",
      "        1.1221e-03, 4.5805e+00, 1.7332e-01, 1.8642e-01, 7.1937e-03, 1.2695e-01,\n",
      "        7.9617e-02, 6.3037e-02, 1.3561e-01, 1.4076e-03, 6.0038e-02, 1.9471e-01,\n",
      "        5.9722e-04, 2.2101e-01, 2.1018e-03, 4.8014e-03, 1.7211e-01, 1.5497e-01,\n",
      "        2.9068e-02, 1.2632e-01, 6.8445e-02, 2.9683e-01])\n",
      "tensor([0.0000, 0.4500, 0.4500, 0.0000, 0.0000, 0.0000, 0.2500, 0.0000, 0.0000,\n",
      "        0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.2500, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500, 0.0000, 0.4500, 0.0000,\n",
      "        0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.2500, 0.2500, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.2500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.0000, 0.2500, 0.0000, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.2500, 0.4500, 0.0000, 0.0000, 0.2500,\n",
      "        0.0000])\n",
      "tensor([0.0000, 0.9000, 0.9000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.5000, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.5000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.0000, 0.5000, 0.0000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.5000, 0.9000, 0.0000, 0.0000, 0.5000,\n",
      "        0.0000])\n",
      "gets to data collection\n",
      "performing step 4 of 20\n",
      "dst node 98 is an end node\n",
      "no FoF link possible for src dst nodes 1 and 98.\n",
      "created 0 of 1 links requested\n",
      "tensor([6.8519e-01, 1.2561e-01, 1.8255e-01, 5.6997e-01, 7.4411e-01, 6.3729e-01,\n",
      "        7.8070e-02, 2.2904e-01, 4.3405e-01, 3.0668e-01, 1.3322e-01, 8.1906e-02,\n",
      "        1.7318e-01, 5.2264e-02, 5.8426e-01, 7.3509e-02, 6.7113e-01, 6.1605e-02,\n",
      "        8.8297e-01, 5.9410e+00, 6.9529e-01, 6.5164e-01, 6.8450e-01, 9.3781e-01,\n",
      "        8.5036e-01, 1.8786e-02, 5.0001e+00, 6.9886e-01, 3.1551e-01, 3.4245e-01,\n",
      "        1.4320e-01, 1.1869e-01, 1.2324e-01, 3.0359e-01, 3.9971e-01, 6.8261e-01,\n",
      "        3.8282e-02, 5.5942e-01, 7.6908e-01, 7.3938e-01, 7.4835e-01, 5.6617e-02,\n",
      "        5.9213e-01, 1.6494e-01, 6.7629e-01, 7.4448e-01, 3.4786e-04, 1.4126e-01,\n",
      "        1.2128e-01, 2.3588e-02, 1.2728e-01, 5.0230e-02, 5.7888e-02, 5.4768e-01,\n",
      "        4.1022e-01, 5.4510e-03, 4.3661e-01, 5.9634e-02, 1.3064e-01, 1.5551e-01,\n",
      "        2.0318e-03, 1.1027e-01, 2.2330e-01, 1.6913e-01, 7.0888e-01, 1.3337e-01,\n",
      "        7.4692e-01, 6.4458e-03, 4.1954e-04, 6.0705e-01, 6.9892e-01, 3.6399e-01,\n",
      "        1.0658e-01, 2.3084e-01, 3.2299e-01, 3.9022e-01, 1.4530e-02, 6.8833e-01,\n",
      "        9.3754e-04, 5.4918e+00, 2.2912e-01, 1.3865e-01, 5.1362e-01, 5.2842e-02,\n",
      "        6.5711e-01, 2.1283e-01, 6.6676e-02, 7.8060e-01, 6.6806e-01, 2.3218e-01,\n",
      "        6.6513e-01, 1.4899e-01, 1.7557e-03, 2.6111e-01, 1.1976e-01, 7.6362e-02,\n",
      "        4.3368e-01, 6.7263e-01, 1.3853e-01, 4.0568e-01])\n",
      "tensor([0.4500, 0.4500, 0.2500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000,\n",
      "        0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.5000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000,\n",
      "        0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 5 of 20\n",
      "creating bidirectional link between nodes 69 (src) and tensor([55]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.9437e-01, 1.0648e-01, 1.8123e-01, 1.9917e-01, 1.3654e-01, 1.5594e-01,\n",
      "        6.0052e-02, 1.1968e-01, 3.9072e-01, 7.8927e-02, 1.1052e-01, 8.9631e-02,\n",
      "        1.5641e-01, 6.2751e-02, 4.7472e-01, 8.6624e-02, 2.9481e-01, 6.3597e-02,\n",
      "        5.9371e-02, 5.9385e+00, 1.9722e-01, 4.5786e-01, 1.3210e-01, 1.5741e-01,\n",
      "        7.8701e-02, 3.4383e-02, 4.9971e+00, 1.0706e-01, 2.6966e-01, 2.4063e-01,\n",
      "        1.3409e-01, 1.1577e-01, 1.1401e-01, 1.8963e-01, 1.9026e-01, 1.8670e-02,\n",
      "        1.0373e-01, 1.8170e-01, 4.9188e-02, 3.7991e-02, 1.9322e-01, 4.3194e-02,\n",
      "        4.7310e-01, 1.5429e-01, 1.8993e-01, 1.0617e-01, 3.4588e-04, 1.3079e-01,\n",
      "        1.2124e-01, 2.1062e-02, 1.0535e-01, 3.0766e-02, 3.7931e-02, 1.8495e-01,\n",
      "        3.4460e-01, 2.3750e-01, 2.2272e-01, 4.0252e-02, 1.2751e-01, 1.4463e-01,\n",
      "        1.9885e-03, 1.1014e-01, 5.5674e-01, 1.5411e-01, 1.7437e-01, 1.1086e-01,\n",
      "        4.7861e-01, 1.0898e-02, 4.1795e-04, 4.4966e-01, 9.5608e-02, 3.2558e-01,\n",
      "        9.2332e-02, 1.6864e-01, 2.1233e-04, 4.8209e-01, 1.2578e-02, 1.3578e-01,\n",
      "        8.4858e-04, 5.7531e+00, 2.0962e-01, 1.3296e-01, 2.6034e-01, 3.3276e-02,\n",
      "        1.8872e-01, 1.8749e-01, 6.5505e-02, 1.3961e-01, 1.7555e-01, 2.1441e-01,\n",
      "        3.2660e-01, 1.4649e-01, 1.5495e-03, 1.5557e-01, 9.7490e-02, 7.6413e-02,\n",
      "        2.3415e-01, 1.7035e-02, 1.2253e-01, 5.6052e-03])\n",
      "tensor([0.2500, 0.4500, 0.2500, 0.0000, 0.2500, 0.2500, 0.4500, 0.0000, 0.0000,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500,\n",
      "        0.2500, 0.4500, 0.2500, 0.4500, 0.2500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.2500, 0.4500, 0.4500, 0.2500, 0.4500, 0.0000, 0.4500, 0.2500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.2500,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.2500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500, 0.2500, 0.0000,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.2500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.2500, 0.4500, 0.4500, 0.2500, 0.2500, 0.4500,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.5000, 0.9000, 0.5000, 0.0000, 0.5000, 0.5000, 0.9000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000,\n",
      "        0.5000, 0.9000, 0.5000, 0.9000, 0.5000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.5000, 0.9000, 0.9000, 0.5000, 0.9000, 0.0000, 0.9000, 0.5000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.5000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.5000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000, 0.5000, 0.0000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.5000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.5000, 0.9000, 0.9000, 0.5000, 0.5000, 0.9000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 6 of 20\n",
      "creating bidirectional link between nodes 13 (src) and tensor([70]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([8.0711e-02, 1.0870e-01, 1.8134e-01, 1.9242e-01, 5.4055e-02, 4.5085e-02,\n",
      "        6.2147e-02, 1.5690e-01, 2.9832e-01, 7.6683e-02, 1.1317e-01, 8.8785e-02,\n",
      "        1.5834e-01, 6.1611e-02, 6.2711e-02, 8.5205e-02, 2.8946e-01, 6.3373e-02,\n",
      "        3.0672e-02, 5.9372e+00, 8.4688e-02, 1.9719e-01, 3.8818e-02, 2.2511e-01,\n",
      "        1.6392e-01, 1.3324e-01, 4.9957e+00, 2.1444e-01, 2.2962e-01, 1.9641e-01,\n",
      "        1.3512e-01, 1.1610e-01, 1.1506e-01, 1.8746e-01, 1.9052e-01, 1.4517e-01,\n",
      "        9.7577e-02, 4.6627e-02, 1.8674e-01, 1.7194e-01, 9.2848e-02, 4.4738e-02,\n",
      "        4.8092e-01, 1.5550e-01, 7.5907e-02, 2.2359e-01, 3.3617e-04, 1.3198e-01,\n",
      "        1.2124e-01, 1.8864e-02, 1.0791e-01, 3.3039e-02, 4.0266e-02, 4.6475e-02,\n",
      "        3.5482e-01, 3.2169e-01, 2.2218e-01, 4.2511e-02, 1.2787e-01, 1.4587e-01,\n",
      "        1.9498e-03, 1.1016e-01, 1.6162e-01, 1.5584e-01, 7.2118e-02, 1.1349e-01,\n",
      "        3.8138e-02, 2.4093e-01, 4.1586e-04, 1.8948e-01, 1.7411e-02, 2.4239e-01,\n",
      "        9.3970e-02, 1.4607e-01, 5.4566e-02, 1.2641e-02, 1.0933e-02, 4.2065e-02,\n",
      "        7.5894e-04, 5.7891e+00, 2.1187e-01, 1.3360e-01, 2.5947e-01, 3.5559e-02,\n",
      "        7.1179e-02, 1.9044e-01, 6.5636e-02, 6.3618e-02, 6.4547e-02, 2.1645e-01,\n",
      "        2.1908e-01, 1.4677e-01, 1.3796e-03, 1.4606e-01, 1.0009e-01, 7.6408e-02,\n",
      "        2.3490e-01, 1.4177e-01, 1.2437e-01, 7.5674e-02])\n",
      "tensor([0.4500, 0.4500, 0.2500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.2500, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.2500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.2500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.5000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.5000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.5000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.5000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 7 of 20\n",
      "dst node 62 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 62.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.2303e-01, 1.0846e-01, 1.8133e-01, 1.9018e-01, 9.4099e-02, 8.4403e-02,\n",
      "        6.1912e-02, 2.0821e-01, 2.7151e-01, 7.6480e-02, 1.1288e-01, 8.8880e-02,\n",
      "        1.5812e-01, 6.1739e-02, 1.3365e-01, 8.5364e-02, 2.8945e-01, 6.3398e-02,\n",
      "        7.2354e-02, 5.9357e+00, 1.2732e-01, 3.7019e-02, 7.7565e-02, 2.1855e-01,\n",
      "        1.5621e-01, 1.4852e-01, 4.9950e+00, 2.0517e-01, 1.9610e-01, 1.4760e-01,\n",
      "        1.3501e-01, 1.1606e-01, 1.1494e-01, 1.8651e-01, 1.9068e-01, 1.3550e-01,\n",
      "        9.8276e-02, 8.6705e-02, 1.7632e-01, 1.6177e-01, 1.3594e-01, 4.4571e-02,\n",
      "        4.8066e-01, 1.5537e-01, 1.1783e-01, 2.1374e-01, 3.2577e-04, 1.3185e-01,\n",
      "        1.2124e-01, 1.7028e-02, 1.0763e-01, 3.2787e-02, 4.0005e-02, 8.6674e-02,\n",
      "        3.3453e-01, 2.4125e-01, 2.2191e-01, 4.2261e-02, 1.2783e-01, 1.4573e-01,\n",
      "        1.9070e-03, 1.1016e-01, 3.2489e-02, 1.5565e-01, 1.1354e-01, 1.1320e-01,\n",
      "        1.1568e-01, 2.3555e-01, 4.0713e-04, 3.0083e-02, 5.4851e-02, 2.3377e-01,\n",
      "        9.3788e-02, 1.4962e-01, 4.9366e-02, 9.7115e-02, 9.5297e-03, 8.1065e-02,\n",
      "        6.9616e-04, 5.7949e+00, 2.1162e-01, 1.3353e-01, 2.5904e-01, 3.5306e-02,\n",
      "        1.1279e-01, 1.9012e-01, 6.5621e-02, 1.0449e-01, 1.0547e-01, 2.1623e-01,\n",
      "        2.1833e-01, 1.4674e-01, 1.2448e-03, 1.4504e-01, 9.9801e-02, 7.6408e-02,\n",
      "        2.3539e-01, 1.3219e-01, 1.2417e-01, 6.9274e-02])\n",
      "tensor([0.4500, 0.4500, 0.2500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.5000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 8 of 20\n",
      "dst node 78 is an end node\n",
      "no FoF link possible for src dst nodes 29 and 78.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.0135e-01, 9.1386e-02, 1.0944e-01, 1.3287e-01, 7.4174e-02, 6.4194e-02,\n",
      "        4.6270e-02, 2.1899e-01, 2.1574e-01, 1.5773e-01, 9.5681e-02, 7.2374e-02,\n",
      "        1.3953e-01, 4.6061e-02, 1.0936e-01, 6.8960e-02, 1.7511e-01, 4.7677e-02,\n",
      "        5.2316e-02, 4.9478e+00, 1.0547e-01, 6.1310e-02, 5.7620e-02, 1.1830e-01,\n",
      "        1.3850e-01, 2.2605e-01, 4.6899e+00, 1.3694e-01, 1.4655e-01, 3.8145e-02,\n",
      "        1.1711e-01, 9.8735e-02, 9.7658e-02, 1.4249e-01, 1.7717e-01, 1.1865e-01,\n",
      "        8.1417e-02, 5.3728e-02, 6.4533e-02, 1.4417e-01, 4.9050e-02, 2.9446e-02,\n",
      "        3.0042e-01, 1.3685e-01, 9.6345e-02, 9.5981e-02, 3.0185e-04, 1.1405e-01,\n",
      "        1.0376e-01, 1.2050e-02, 9.0585e-02, 1.8036e-02, 2.5032e-02, 6.6315e-02,\n",
      "        8.0661e-02, 2.3161e-01, 1.6428e-01, 2.7218e-02, 1.1014e-01, 1.2751e-01,\n",
      "        1.5496e-03, 9.3006e-02, 5.5209e-02, 1.3713e-01, 9.2231e-02, 9.5985e-02,\n",
      "        9.1547e-02, 2.4121e-01, 3.4956e-04, 5.3954e-02, 3.5730e-02, 2.1909e-01,\n",
      "        7.7162e-02, 2.0089e-01, 3.4648e-02, 7.3187e-02, 6.8387e-03, 6.0983e-02,\n",
      "        4.2167e-04, 4.5798e+00, 1.9139e-01, 1.1568e-01, 1.7691e-01, 2.0475e-02,\n",
      "        5.2797e-02, 1.7056e-01, 4.9837e-02, 8.3517e-02, 4.0240e-02, 1.9585e-01,\n",
      "        1.6521e-01, 1.2848e-01, 1.0002e-03, 2.2007e-03, 8.3004e-02, 6.0292e-02,\n",
      "        1.8083e-01, 1.1542e-01, 1.0661e-01, 5.4077e-02])\n",
      "tensor([0.4500, 0.4500, 0.2500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.0000, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.5000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.0000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 9 of 20\n",
      "dst node 67 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 67.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.2109e-01, 1.1030e-01, 1.8479e-01, 4.2294e-02, 3.5213e-01, 8.2600e-02,\n",
      "        6.3603e-02, 8.9533e-02, 1.4767e-01, 1.5881e-01, 1.1474e-01, 9.0626e-02,\n",
      "        1.6013e-01, 6.3391e-02, 1.2965e-01, 8.7092e-02, 1.5228e-01, 6.5069e-02,\n",
      "        7.0335e-02, 4.9969e+00, 1.2535e-01, 7.5146e-02, 7.5794e-02, 5.2247e-01,\n",
      "        1.5897e-01, 3.5281e-02, 4.8656e+00, 4.8669e-01, 1.1700e-01, 1.1788e-01,\n",
      "        1.3693e-01, 1.1791e-01, 1.1679e-01, 4.4649e-02, 6.8118e-02, 1.3839e-01,\n",
      "        9.9991e-02, 3.5671e-01, 4.9882e-01, 1.6480e-01, 4.3848e-01, 4.6197e-02,\n",
      "        4.7363e-01, 1.5735e-01, 1.1591e-01, 5.3322e-01, 3.1735e-04, 1.3376e-01,\n",
      "        1.2310e-01, 1.5133e-02, 1.0947e-01, 3.4384e-02, 4.1624e-02, 8.4805e-02,\n",
      "        3.6831e-01, 1.2080e-01, 8.8086e-02, 4.3887e-02, 1.2971e-01, 1.4769e-01,\n",
      "        1.8575e-03, 1.1198e-01, 6.8993e-02, 1.5764e-01, 1.1164e-01, 1.1506e-01,\n",
      "        1.1125e-01, 9.0917e-02, 4.0081e-04, 6.7596e-02, 5.3125e-02, 1.1857e-01,\n",
      "        9.5576e-02, 4.2791e-02, 5.1518e-02, 9.2300e-02, 8.5111e-03, 7.9281e-02,\n",
      "        6.1696e-04, 5.1297e+00, 2.1380e-01, 1.3544e-01, 1.2578e-01, 3.6912e-02,\n",
      "        3.9881e-01, 1.9223e-01, 6.7301e-02, 1.0262e-01, 3.9728e-01, 2.1842e-01,\n",
      "        8.5103e-02, 1.4869e-01, 1.1017e-03, 3.0025e-01, 1.0162e-01, 7.8125e-02,\n",
      "        1.0621e-01, 1.3506e-01, 1.2606e-01, 7.1612e-02])\n",
      "tensor([0.4500, 0.4500, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.0000, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.0000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 10 of 20\n",
      "creating bidirectional link between nodes 42 (src) and tensor([52]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.3059e-01, 1.1967e-01, 2.8952e-02, 6.4593e-02, 5.4621e-02, 9.1462e-02,\n",
      "        7.2194e-02, 1.1874e-01, 1.6857e-01, 1.9884e-01, 1.2419e-01, 9.9665e-02,\n",
      "        1.7033e-01, 7.1979e-02, 1.3927e-01, 9.6072e-02, 1.6729e-01, 7.3681e-02,\n",
      "        7.8987e-02, 5.9016e+00, 1.3493e-01, 8.4337e-02, 8.4542e-02, 1.7958e-01,\n",
      "        1.6916e-01, 7.4362e-02, 9.5500e+00, 1.7100e-01, 2.3149e-01, 2.8079e-01,\n",
      "        1.4674e-01, 1.2741e-01, 1.2627e-01, 6.8110e-02, 9.3719e-02, 1.4825e-01,\n",
      "        1.0919e-01, 4.4092e-02, 1.3165e-01, 1.7509e-01, 8.7636e-02, 5.4496e-02,\n",
      "        6.0113e-01, 1.6751e-01, 1.2532e-01, 1.7145e-01, 3.0918e-04, 1.4352e-01,\n",
      "        1.3269e-01, 1.3012e-02, 1.1883e-01, 4.2486e-02, 4.9851e-02, 9.3705e-02,\n",
      "        4.5615e-01, 1.4755e-01, 1.0904e-01, 5.2151e-02, 1.3941e-01, 1.5768e-01,\n",
      "        1.7841e-03, 1.2138e-01, 7.8067e-02, 1.6780e-01, 1.2099e-01, 1.2451e-01,\n",
      "        1.2056e-01, 1.2358e-01, 3.9553e-04, 7.6658e-02, 6.1494e-02, 1.4370e-01,\n",
      "        1.0470e-01, 7.6158e-02, 5.9912e-02, 1.0129e-01, 1.7409e-02, 8.8085e-02,\n",
      "        1.0132e-03, 5.4287e+00, 2.2490e-01, 1.4523e-01, 1.4392e-01, 4.5055e-02,\n",
      "        6.7467e-02, 2.0298e-01, 7.5954e-02, 1.1181e-01, 5.8477e-02, 2.2960e-01,\n",
      "        1.0658e-01, 1.5870e-01, 9.3178e-04, 1.2165e-01, 1.1085e-01, 8.6954e-02,\n",
      "        1.2727e-01, 1.4485e-01, 1.3569e-01, 8.0341e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 11 of 20\n",
      "dst node 14 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 14.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1788e-01, 1.0720e-01, 1.4753e-02, 5.1807e-02, 9.4048e-02, 7.9611e-02,\n",
      "        6.0758e-02, 1.0413e-01, 1.5383e-01, 1.5009e-01, 1.1161e-01, 8.7629e-02,\n",
      "        1.5674e-01, 6.0547e-02, 1.2638e-01, 8.4116e-02, 1.5323e-01, 6.2211e-02,\n",
      "        6.7413e-02, 5.9096e+00, 1.2213e-01, 7.2592e-02, 7.2842e-02, 2.2323e-01,\n",
      "        1.5560e-01, 5.9680e-02, 9.5500e+00, 2.0971e-01, 1.7772e-01, 2.0055e-01,\n",
      "        1.3367e-01, 1.1476e-01, 1.1365e-01, 5.5130e-02, 7.9998e-02, 1.3514e-01,\n",
      "        9.6942e-02, 8.6924e-02, 1.8191e-01, 1.6140e-01, 1.3639e-01, 4.3447e-02,\n",
      "        4.7221e-01, 1.5399e-01, 1.1273e-01, 2.1909e-01, 3.0319e-04, 1.3052e-01,\n",
      "        1.1993e-01, 1.1916e-02, 1.0637e-01, 3.1702e-02, 3.8903e-02, 8.1802e-02,\n",
      "        2.6024e-01, 1.3261e-01, 9.5500e-02, 4.1152e-02, 1.2650e-01, 1.4438e-01,\n",
      "        1.7503e-03, 1.0887e-01, 6.6458e-02, 1.5427e-01, 1.0849e-01, 1.1193e-01,\n",
      "        1.0808e-01, 1.0852e-01, 3.9031e-04, 6.5079e-02, 5.0300e-02, 1.2901e-01,\n",
      "        9.2554e-02, 6.2002e-02, 4.8743e-02, 8.9223e-02, 1.5168e-02, 7.6308e-02,\n",
      "        9.0658e-04, 5.7435e+00, 2.1012e-01, 1.3219e-01, 1.2998e-01, 3.4216e-02,\n",
      "        1.1311e-01, 1.8868e-01, 6.4437e-02, 9.9513e-02, 1.0599e-01, 2.1471e-01,\n",
      "        9.3031e-02, 1.4537e-01, 8.5928e-04, 1.4839e-01, 9.8565e-02, 7.5198e-02,\n",
      "        1.1335e-01, 1.3182e-01, 1.2287e-01, 6.8730e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 12 of 20\n",
      "dst node 89 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 89.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1933e-01, 1.0862e-01, 1.6393e-02, 5.3276e-02, 9.0057e-02, 8.0968e-02,\n",
      "        6.2068e-02, 1.0581e-01, 1.5553e-01, 1.5463e-01, 1.1305e-01, 8.9008e-02,\n",
      "        1.5830e-01, 6.1857e-02, 1.2785e-01, 8.5485e-02, 1.5484e-01, 6.3530e-02,\n",
      "        6.8736e-02, 5.9175e+00, 1.2359e-01, 7.3936e-02, 7.4180e-02, 2.1876e-01,\n",
      "        1.5715e-01, 6.1375e-02, 5.0185e+00, 2.0571e-01, 1.8620e-01, 2.1385e-01,\n",
      "        1.3517e-01, 1.1621e-01, 1.1510e-01, 5.6623e-02, 8.1575e-02, 1.3664e-01,\n",
      "        9.8346e-02, 8.2638e-02, 1.7688e-01, 1.6297e-01, 1.3153e-01, 4.4712e-02,\n",
      "        4.8095e-01, 1.5554e-01, 1.1417e-01, 2.1425e-01, 2.9550e-04, 1.3201e-01,\n",
      "        1.2139e-01, 1.0901e-02, 1.0780e-01, 3.2936e-02, 4.0154e-02, 8.3166e-02,\n",
      "        2.8483e-01, 1.3433e-01, 9.7055e-02, 4.2412e-02, 1.2798e-01, 1.4590e-01,\n",
      "        1.7183e-03, 1.1030e-01, 6.7787e-02, 1.5582e-01, 1.0992e-01, 1.1337e-01,\n",
      "        1.0951e-01, 1.1026e-01, 3.8349e-04, 6.6404e-02, 5.1581e-02, 1.3070e-01,\n",
      "        9.3945e-02, 6.3634e-02, 5.0024e-02, 9.0604e-02, 1.3983e-02, 7.7656e-02,\n",
      "        8.4346e-04, 5.7863e+00, 2.1181e-01, 1.3369e-01, 1.3158e-01, 3.5455e-02,\n",
      "        1.0856e-01, 1.9031e-01, 6.5754e-02, 1.0093e-01, 1.0128e-01, 2.1642e-01,\n",
      "        9.4586e-02, 1.4690e-01, 7.8563e-04, 1.4657e-01, 9.9974e-02, 7.6543e-02,\n",
      "        1.1495e-01, 1.3332e-01, 1.2434e-01, 7.0057e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 13 of 20\n",
      "creating bidirectional link between nodes 70 (src) and tensor([2]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.1917e-01, 1.0847e-01, 1.6212e-02, 5.3113e-02, 9.0508e-02, 8.0817e-02,\n",
      "        6.1922e-02, 1.0563e-01, 1.5534e-01, 1.5428e-01, 1.1289e-01, 8.8854e-02,\n",
      "        1.5813e-01, 6.1711e-02, 1.2769e-01, 8.5333e-02, 1.5466e-01, 6.3380e-02,\n",
      "        6.8589e-02, 5.9196e+00, 1.2343e-01, 7.3786e-02, 7.4033e-02, 2.1927e-01,\n",
      "        1.5698e-01, 6.1188e-02, 5.0060e+00, 2.0616e-01, 1.9389e-01, 2.2501e-01,\n",
      "        1.3500e-01, 1.1605e-01, 1.1494e-01, 5.6458e-02, 8.1400e-02, 1.3648e-01,\n",
      "        9.8190e-02, 8.3121e-02, 1.7744e-01, 1.6280e-01, 1.3208e-01, 4.4571e-02,\n",
      "        4.8066e-01, 1.5536e-01, 1.1401e-01, 2.1480e-01, 2.9111e-04, 1.3185e-01,\n",
      "        1.2123e-01, 1.0006e-02, 1.0764e-01, 3.2799e-02, 4.0018e-02, 8.3014e-02,\n",
      "        2.6921e-01, 1.3414e-01, 9.6882e-02, 4.2272e-02, 1.2781e-01, 1.4573e-01,\n",
      "        1.6776e-03, 1.1014e-01, 6.7639e-02, 1.5565e-01, 1.0976e-01, 1.1321e-01,\n",
      "        1.0935e-01, 1.1006e-01, 3.8224e-04, 6.6257e-02, 5.1439e-02, 1.3051e-01,\n",
      "        9.3790e-02, 6.3451e-02, 4.9879e-02, 9.0451e-02, 1.3548e-02, 7.7506e-02,\n",
      "        8.1799e-04, 5.7948e+00, 2.1162e-01, 1.3352e-01, 1.3140e-01, 3.5318e-02,\n",
      "        1.0907e-01, 1.9013e-01, 6.5608e-02, 1.0076e-01, 1.0181e-01, 2.1623e-01,\n",
      "        9.4413e-02, 1.4673e-01, 7.1706e-04, 1.4671e-01, 9.9814e-02, 7.6393e-02,\n",
      "        1.1477e-01, 1.3315e-01, 1.2417e-01, 6.9910e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 14 of 20\n",
      "dst node 36 is an end node\n",
      "no FoF link possible for src dst nodes 20 and 36.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1919e-01, 1.0848e-01, 1.6232e-02, 5.3131e-02, 9.0453e-02, 8.0834e-02,\n",
      "        6.1938e-02, 1.0565e-01, 1.5536e-01, 1.5431e-01, 1.1291e-01, 8.8872e-02,\n",
      "        1.5815e-01, 6.1728e-02, 1.2771e-01, 8.5350e-02, 1.5468e-01, 6.3397e-02,\n",
      "        6.8605e-02, 5.9238e+00, 1.2345e-01, 7.3803e-02, 7.4049e-02, 2.1921e-01,\n",
      "        1.5700e-01, 6.1206e-02, 5.0000e+00, 2.0611e-01, 2.0088e-01, 2.3443e-01,\n",
      "        1.3502e-01, 1.1607e-01, 1.1496e-01, 5.6476e-02, 8.1419e-02, 1.3649e-01,\n",
      "        9.8207e-02, 8.3066e-02, 1.7738e-01, 1.6281e-01, 1.3202e-01, 4.4587e-02,\n",
      "        4.8067e-01, 1.5538e-01, 1.1403e-01, 2.1474e-01, 2.8631e-04, 1.3187e-01,\n",
      "        1.2125e-01, 9.1606e-03, 1.0766e-01, 3.2814e-02, 4.0032e-02, 8.3031e-02,\n",
      "        2.5933e-01, 1.3415e-01, 9.6901e-02, 4.2287e-02, 1.2783e-01, 1.4575e-01,\n",
      "        1.6487e-03, 1.1016e-01, 6.7656e-02, 1.5567e-01, 1.0978e-01, 1.1323e-01,\n",
      "        1.0937e-01, 1.1008e-01, 3.8023e-04, 6.6273e-02, 5.1455e-02, 1.3053e-01,\n",
      "        9.3808e-02, 6.3472e-02, 4.9896e-02, 9.0468e-02, 1.3853e-02, 7.7523e-02,\n",
      "        8.1520e-04, 5.7916e+00, 2.1164e-01, 1.3354e-01, 1.3142e-01, 3.5333e-02,\n",
      "        1.0901e-01, 1.9015e-01, 6.5624e-02, 1.0078e-01, 1.0175e-01, 2.1625e-01,\n",
      "        9.4432e-02, 1.4674e-01, 6.5660e-04, 1.4670e-01, 9.9834e-02, 7.6410e-02,\n",
      "        1.1479e-01, 1.3317e-01, 1.2419e-01, 6.9926e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 15 of 20\n",
      "creating bidirectional link between nodes 36 (src) and tensor([3]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.1919e-01, 1.0848e-01, 1.6230e-02, 5.3129e-02, 9.0462e-02, 8.0832e-02,\n",
      "        6.1937e-02, 1.0565e-01, 1.5536e-01, 1.5431e-01, 1.1291e-01, 8.8870e-02,\n",
      "        1.5815e-01, 6.1726e-02, 1.2770e-01, 8.5348e-02, 1.5468e-01, 6.3395e-02,\n",
      "        6.8603e-02, 5.9270e+00, 1.2344e-01, 7.3801e-02, 7.4047e-02, 2.1921e-01,\n",
      "        1.5700e-01, 6.1206e-02, 4.9971e+00, 2.0612e-01, 2.0723e-01, 2.4244e-01,\n",
      "        1.3502e-01, 1.1606e-01, 1.1495e-01, 5.6474e-02, 8.1417e-02, 1.3649e-01,\n",
      "        9.8206e-02, 8.3073e-02, 1.7739e-01, 1.6281e-01, 1.3203e-01, 4.4585e-02,\n",
      "        4.8067e-01, 1.5538e-01, 1.1403e-01, 2.1474e-01, 2.8322e-04, 1.3186e-01,\n",
      "        1.2124e-01, 8.4037e-03, 1.0765e-01, 3.2813e-02, 4.0030e-02, 8.3029e-02,\n",
      "        2.4923e-01, 1.3415e-01, 9.6899e-02, 4.2285e-02, 1.2783e-01, 1.4575e-01,\n",
      "        1.6093e-03, 1.1016e-01, 6.7654e-02, 1.5567e-01, 1.0978e-01, 1.1323e-01,\n",
      "        1.0936e-01, 1.1008e-01, 3.7641e-04, 6.6271e-02, 5.1453e-02, 1.3053e-01,\n",
      "        9.3806e-02, 6.3469e-02, 4.9895e-02, 9.0466e-02, 1.5357e-02, 7.7521e-02,\n",
      "        8.4025e-04, 5.7924e+00, 2.1164e-01, 1.3354e-01, 1.3142e-01, 3.5331e-02,\n",
      "        1.0902e-01, 1.9015e-01, 6.5622e-02, 1.0078e-01, 1.0175e-01, 2.1625e-01,\n",
      "        9.4430e-02, 1.4674e-01, 1.0896e-03, 1.4670e-01, 9.9831e-02, 7.6408e-02,\n",
      "        1.1479e-01, 1.3317e-01, 1.2419e-01, 6.9924e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 16 of 20\n",
      "creating bidirectional link between nodes 13 (src) and tensor([2]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.3081e-01, 1.1988e-01, 2.5743e-02, 6.3397e-02, 1.0149e-01, 9.1666e-02,\n",
      "        7.2387e-02, 1.1698e-01, 1.6771e-01, 1.9923e-01, 1.2440e-01, 9.9867e-02,\n",
      "        1.7056e-01, 7.2171e-02, 1.3949e-01, 9.6273e-02, 1.6702e-01, 7.3872e-02,\n",
      "        7.9186e-02, 5.7990e+00, 1.3515e-01, 8.4490e-02, 8.4741e-02, 2.3287e-01,\n",
      "        1.6939e-01, 7.1641e-02, 9.5500e+00, 2.1951e-01, 4.3763e-01, 4.8786e-01,\n",
      "        1.4696e-01, 1.2762e-01, 1.2648e-01, 6.6811e-02, 9.2263e-02, 1.4846e-01,\n",
      "        1.0939e-01, 9.3951e-02, 1.9019e-01, 1.7532e-01, 1.4390e-01, 5.4680e-02,\n",
      "        6.0084e-01, 1.6774e-01, 1.2554e-01, 2.2831e-01, 2.7125e-04, 1.4374e-01,\n",
      "        1.3290e-01, 1.9912e-02, 1.1903e-01, 4.2668e-02, 5.0030e-02, 9.3910e-02,\n",
      "        3.1861e-01, 1.4608e-01, 1.0806e-01, 5.2332e-02, 1.3962e-01, 1.5791e-01,\n",
      "        1.5568e-03, 1.2159e-01, 7.8217e-02, 1.6803e-01, 1.2120e-01, 1.2472e-01,\n",
      "        1.2078e-01, 1.2151e-01, 3.6614e-04, 7.6808e-02, 6.1686e-02, 1.4238e-01,\n",
      "        1.0490e-01, 7.3948e-02, 6.0096e-02, 1.0150e-01, 2.1518e-01, 8.8286e-02,\n",
      "        4.8796e-02, 5.4218e+00, 2.2514e-01, 1.4545e-01, 1.4329e-01, 4.5234e-02,\n",
      "        1.2042e-01, 2.0321e-01, 7.6146e-02, 1.1203e-01, 1.1301e-01, 2.2984e-01,\n",
      "        1.0554e-01, 1.5892e-01, 1.4545e-03, 1.9078e-01, 1.1105e-01, 8.7152e-02,\n",
      "        1.2631e-01, 1.4507e-01, 1.3591e-01, 8.0534e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 17 of 20\n",
      "creating bidirectional link between nodes 22 (src) and tensor([27]) (dst)\n",
      "created 1 of 1 links requested\n",
      "tensor([1.1785e-01, 1.0717e-01, 1.5138e-02, 5.1949e-02, 8.9190e-02, 7.9587e-02,\n",
      "        6.0733e-02, 1.0434e-01, 1.5394e-01, 1.5005e-01, 1.1159e-01, 8.7606e-02,\n",
      "        1.5672e-01, 6.0524e-02, 1.2635e-01, 8.4092e-02, 1.5326e-01, 6.2188e-02,\n",
      "        6.7389e-02, 5.8365e+00, 1.2210e-01, 7.2574e-02, 7.2819e-02, 2.1764e-01,\n",
      "        1.5557e-01, 6.0004e-02, 9.5500e+00, 2.0458e-01, 2.2759e-01, 2.6764e-01,\n",
      "        1.3365e-01, 1.1474e-01, 1.1363e-01, 5.5286e-02, 8.0170e-02, 1.3512e-01,\n",
      "        9.6919e-02, 8.1822e-02, 1.7592e-01, 1.6138e-01, 1.3066e-01, 4.3425e-02,\n",
      "        4.7224e-01, 1.5396e-01, 1.1271e-01, 2.1318e-01, 2.6660e-04, 1.3050e-01,\n",
      "        1.1991e-01, 1.6058e-02, 1.0635e-01, 3.1678e-02, 3.8882e-02, 8.1777e-02,\n",
      "        2.5994e-01, 1.3278e-01, 9.5617e-02, 4.1131e-02, 1.2647e-01, 1.4435e-01,\n",
      "        1.5128e-03, 1.0884e-01, 6.6442e-02, 1.5424e-01, 1.0847e-01, 1.1191e-01,\n",
      "        1.0805e-01, 1.0877e-01, 3.6125e-04, 6.5060e-02, 5.0278e-02, 1.2917e-01,\n",
      "        9.2530e-02, 6.2266e-02, 4.8722e-02, 8.9199e-02, 2.0039e-01, 7.6285e-02,\n",
      "        9.1377e-02, 5.7428e+00, 2.1009e-01, 1.3217e-01, 1.3006e-01, 3.4195e-02,\n",
      "        1.0770e-01, 1.8865e-01, 6.4413e-02, 9.9487e-02, 1.0046e-01, 2.1468e-01,\n",
      "        9.3153e-02, 1.4534e-01, 1.2808e-03, 1.4251e-01, 9.8539e-02, 7.5173e-02,\n",
      "        1.1347e-01, 1.3180e-01, 1.2284e-01, 6.8706e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 18 of 20\n",
      "dst node 74 is an end node\n",
      "no FoF link possible for src dst nodes 3 and 74.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1934e-01, 1.0863e-01, 1.6351e-02, 5.3260e-02, 9.0602e-02, 8.0971e-02,\n",
      "        6.2070e-02, 1.0579e-01, 1.5551e-01, 1.5463e-01, 1.1306e-01, 8.9010e-02,\n",
      "        1.5830e-01, 6.1859e-02, 1.2785e-01, 8.5487e-02, 1.5484e-01, 6.3533e-02,\n",
      "        6.8738e-02, 5.8624e+00, 1.2359e-01, 7.3938e-02, 7.4182e-02, 2.1939e-01,\n",
      "        1.5716e-01, 6.1339e-02, 9.5500e+00, 2.0629e-01, 2.3166e-01, 2.7097e-01,\n",
      "        1.3517e-01, 1.1621e-01, 1.1510e-01, 5.6606e-02, 8.1556e-02, 1.3665e-01,\n",
      "        9.8349e-02, 8.3213e-02, 1.7755e-01, 1.6297e-01, 1.3218e-01, 4.4714e-02,\n",
      "        4.8095e-01, 1.5554e-01, 1.1417e-01, 2.1492e-01, 2.6267e-04, 1.3202e-01,\n",
      "        1.2139e-01, 1.3957e-02, 1.0780e-01, 3.2939e-02, 4.0157e-02, 8.3168e-02,\n",
      "        2.1414e-01, 1.3431e-01, 9.7042e-02, 4.2414e-02, 1.2798e-01, 1.4590e-01,\n",
      "        1.4809e-03, 1.1030e-01, 6.7789e-02, 1.5582e-01, 1.0992e-01, 1.1337e-01,\n",
      "        1.0951e-01, 1.1023e-01, 3.6109e-04, 6.6406e-02, 5.1584e-02, 1.3068e-01,\n",
      "        9.3948e-02, 6.3603e-02, 5.0026e-02, 9.0607e-02, 1.7504e-01, 7.7659e-02,\n",
      "        9.7974e-02, 5.7868e+00, 2.1181e-01, 1.3369e-01, 1.3157e-01, 3.5457e-02,\n",
      "        1.0916e-01, 1.9032e-01, 6.5757e-02, 1.0093e-01, 1.0190e-01, 2.1642e-01,\n",
      "        9.4572e-02, 1.4690e-01, 1.2062e-03, 1.4702e-01, 9.9975e-02, 7.6546e-02,\n",
      "        1.1494e-01, 1.3332e-01, 1.2434e-01, 7.0060e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 19 of 20\n",
      "dst node 95 is an end node\n",
      "no FoF link possible for src dst nodes 88 and 95.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1917e-01, 1.0847e-01, 1.6216e-02, 5.3115e-02, 9.0445e-02, 8.0817e-02,\n",
      "        6.1922e-02, 1.0563e-01, 1.5534e-01, 1.5428e-01, 1.1289e-01, 8.8854e-02,\n",
      "        1.5813e-01, 6.1711e-02, 1.2769e-01, 8.5332e-02, 1.5466e-01, 6.3380e-02,\n",
      "        6.8588e-02, 5.8836e+00, 1.2343e-01, 7.3786e-02, 7.4034e-02, 2.1919e-01,\n",
      "        1.5698e-01, 6.1191e-02, 5.0120e+00, 2.0610e-01, 2.3540e-01, 2.7387e-01,\n",
      "        1.3500e-01, 1.1605e-01, 1.1494e-01, 5.6460e-02, 8.1402e-02, 1.3648e-01,\n",
      "        9.8190e-02, 8.3055e-02, 1.7737e-01, 1.6280e-01, 1.3201e-01, 4.4571e-02,\n",
      "        4.8066e-01, 1.5536e-01, 1.1401e-01, 2.1473e-01, 2.5817e-04, 1.3185e-01,\n",
      "        1.2123e-01, 1.2776e-02, 1.0764e-01, 3.2799e-02, 4.0017e-02, 8.3014e-02,\n",
      "        2.0653e-01, 1.3414e-01, 9.6883e-02, 4.2271e-02, 1.2781e-01, 1.4573e-01,\n",
      "        1.4584e-03, 1.1014e-01, 6.7639e-02, 1.5565e-01, 1.0976e-01, 1.1321e-01,\n",
      "        1.0935e-01, 1.1007e-01, 3.5717e-04, 6.6256e-02, 5.1438e-02, 1.3051e-01,\n",
      "        9.3790e-02, 6.3455e-02, 4.9879e-02, 9.0450e-02, 1.4689e-01, 7.7506e-02,\n",
      "        9.8681e-02, 5.7930e+00, 2.1162e-01, 1.3352e-01, 1.3141e-01, 3.5317e-02,\n",
      "        1.0900e-01, 1.9013e-01, 6.5608e-02, 1.0076e-01, 1.0174e-01, 2.1623e-01,\n",
      "        9.4415e-02, 1.4673e-01, 1.2134e-03, 1.4667e-01, 9.9816e-02, 7.6393e-02,\n",
      "        1.1477e-01, 1.3315e-01, 1.2417e-01, 6.9909e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n",
      "performing step 20 of 20\n",
      "all FoF nodes are already direcctly connected to node 2.\n",
      "no FoF link possible for src dst nodes 2 and 70.\n",
      "created 0 of 1 links requested\n",
      "tensor([1.1919e-01, 1.0848e-01, 1.6231e-02, 5.3131e-02, 9.0463e-02, 8.0834e-02,\n",
      "        6.1938e-02, 1.0565e-01, 1.5536e-01, 1.5431e-01, 1.1291e-01, 8.8872e-02,\n",
      "        1.5815e-01, 6.1728e-02, 1.2771e-01, 8.5350e-02, 1.5468e-01, 6.3397e-02,\n",
      "        6.8605e-02, 5.8989e+00, 1.2345e-01, 7.3803e-02, 7.4049e-02, 2.1922e-01,\n",
      "        1.5700e-01, 6.1207e-02, 5.0029e+00, 2.0612e-01, 2.3884e-01, 2.7639e-01,\n",
      "        1.3502e-01, 1.1607e-01, 1.1496e-01, 5.6476e-02, 8.1419e-02, 1.3649e-01,\n",
      "        9.8207e-02, 8.3074e-02, 1.7739e-01, 1.6281e-01, 1.3203e-01, 4.4587e-02,\n",
      "        4.8067e-01, 1.5538e-01, 1.1403e-01, 2.1475e-01, 2.5433e-04, 1.3187e-01,\n",
      "        1.2125e-01, 1.2105e-02, 1.0766e-01, 3.2814e-02, 4.0032e-02, 8.3031e-02,\n",
      "        1.9890e-01, 1.3416e-01, 9.6901e-02, 4.2287e-02, 1.2783e-01, 1.4575e-01,\n",
      "        1.4110e-03, 1.1016e-01, 6.7656e-02, 1.5567e-01, 1.0978e-01, 1.1323e-01,\n",
      "        1.0937e-01, 1.1008e-01, 3.5280e-04, 6.6273e-02, 5.1455e-02, 1.3053e-01,\n",
      "        9.3808e-02, 6.3471e-02, 4.9896e-02, 9.0468e-02, 1.5177e-01, 7.7523e-02,\n",
      "        9.4252e-02, 5.7924e+00, 2.1164e-01, 1.3354e-01, 1.3142e-01, 3.5333e-02,\n",
      "        1.0902e-01, 1.9015e-01, 6.5624e-02, 1.0078e-01, 1.0176e-01, 2.1625e-01,\n",
      "        9.4432e-02, 1.4674e-01, 1.3461e-03, 1.4670e-01, 9.9833e-02, 7.6410e-02,\n",
      "        1.1479e-01, 1.3317e-01, 1.2419e-01, 6.9926e-02])\n",
      "tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000,\n",
      "        0.4500, 0.0000, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.0000, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.0000, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.4500, 0.0000, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500, 0.4500, 0.0000, 0.2500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500,\n",
      "        0.4500])\n",
      "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000,\n",
      "        0.9000, 0.0000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.0000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.0000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.9000, 0.0000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000, 0.9000, 0.0000, 0.5000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
      "        0.9000])\n",
      "gets to data collection\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9567, 2.9776, 2.1575, 3.4204, 2.7872])\n",
      "tensor([1, 2, 2, 2, 2])\n",
      "torch.float32\n",
      "tensor([1, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "TechTable =  np.array([[0.3,0],[0.35,0.15],[0.45, 0.65]])\n",
    "wealth=torch.tensor([ 6.4072, 17.6514,  8.5695, 27.9308, 13.7166])\n",
    "alpha=torch.tensor([1.0997, 0.9967, 1.0678, 0.9097, 1.0579])\n",
    "gamma = torch.tensor([0.3,0.35,0.45])\n",
    "cost = torch.tensor([0,0.15,0.65])\n",
    "\n",
    "income,index = torch.max((alpha[:,None]*wealth[:,None]**TechTable[:,0] - TechTable[:,1]), axis=1)\n",
    "income=income.to(torch.float32)\n",
    "\n",
    "print(income)\n",
    "print(index)\n",
    "\n",
    "\n",
    "income,tech_index = torch.max((alpha[:,None]*wealth[:,None]**gamma - cost), axis=1)\n",
    "\n",
    "print(income.dtype)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6091, 2.0877, 2.1235, 1.1489, 7.8204, 9.6203, 7.9892, 2.9878, 7.7790,\n",
      "        0.8866])\n",
      "tensor(0.8000)\n"
     ]
    }
   ],
   "source": [
    "def sample_distribution_tensor(type, distParameters, nSamples, round=False, decimals=None):\n",
    "    \"\"\"\n",
    "    create and return samples from different distributions\n",
    "\n",
    "    :param type: Type of distribution to sample\n",
    "    :param distParameters: array of parameters as required/supported by requested distribution type\n",
    "    :param nSamples: number of samples to return (as 1d tensor)\n",
    "    :param round: optional, whether the samples are to be rounded\n",
    "    :param decimals: optional, required if round is specified. decimal places to round to\n",
    "    \"\"\"\n",
    "    if type == 'uniform':\n",
    "        dist = torch.distributions.uniform.Uniform(torch.tensor(distParameters[0]),torch.tensor(distParameters[1])).sample(torch.tensor([nSamples]))\n",
    "    elif type == 'normal':\n",
    "        dist = torch.distributions.normal.Normal(torch.tensor(distParameters[0]),torch.tensor(distParameters[1])).sample(torch.tensor([nSamples]))\n",
    "    elif type == 'bernoulli':\n",
    "        dist = torch.distributions.bernoulli.Bernoulli(probs=distParameters[0],logits=distParameters[1],validate_args=None).sample(torch.tensor([nSamples]))\n",
    "    elif type == 'multinomial':\n",
    "        dist = torch.gather(torch.Tensor(distParameters[1]), 0, torch.multinomial(torch.tensor(distParameters[0]), nSamples, replacement=True))\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('Currently only uniform, normal, multinomial, and bernoulli distributions are supported')\n",
    "\n",
    "    if round:\n",
    "        if decimals == None:\n",
    "            raise ValueError('rounding requires decimals of rounding accuracy to be specified')\n",
    "        else:\n",
    "            return torch.round(dist,decimals=decimals)\n",
    "    else:\n",
    "        return dist\n",
    "\n",
    "theta_dist = {'type':'multinomial','parameters':[[0.01 ,0.1, 0.79, 0.1],[0.1, 0.5, 0.8, 1]],'round':False,'decimals':None} \n",
    "theta_vals = torch.tensor([0.1, 0.5, 0.8, 1])\n",
    "capital_dist = {'type':'uniform','parameters':[0.1,10.],'round':False,'decimals':None}\n",
    "\n",
    "\n",
    "agentsCapital = sample_distribution_tensor(capital_dist['type'],capital_dist['parameters'],10,capital_dist['round'],decimals=capital_dist['decimals'])\n",
    "print(agentsCapital)\n",
    "modelTheta = sample_distribution_tensor(theta_dist['type'],theta_dist['parameters'],10,round=theta_dist['round'],decimals=theta_dist['decimals'])\n",
    "print(modelTheta[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.2311), tensor(1.1246), tensor(0.7160)]\n",
      "tensor([1.2311, 1.1246, 0.7160])\n"
     ]
    }
   ],
   "source": [
    "tech_gamma=torch.tensor([0.3,0.35,0.45])\n",
    "tech_cost=torch.tensor([0,0.15,0.65])\n",
    "=1\n",
    "k=2\n",
    "\n",
    "\n",
    "\n",
    "f = []\n",
    "for i in range(tech_gamma.size(dim=0)): \n",
    "    #in the end, they may need their own tech tables\n",
    "    entry =  * k**tech_gamma[i] - tech_cost[i]\n",
    "    f.append(entry)\n",
    "print(f)\n",
    "entry =  * k**tech_gamma - tech_cost\n",
    "print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3000, 0.3500, 0.4500],\n",
       "         [0.0000, 0.1500, 0.6500]],\n",
       "\n",
       "        [[0.3000, 0.3500, 0.4500],\n",
       "         [0.0000, 0.1500, 0.6500]],\n",
       "\n",
       "        [[0.3000, 0.3500, 0.4500],\n",
       "         [0.0000, 0.1500, 0.6500]],\n",
       "\n",
       "        [[0.3000, 0.3500, 0.4500],\n",
       "         [0.0000, 0.1500, 0.6500]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([tech_gamma,tech_cost]).repeat(4,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.5, 0.8, 1]\n",
      "['a', 'b', 'c']\n",
      "['b', 'c']\n",
      "['b']\n"
     ]
    }
   ],
   "source": [
    "data={'a':0,'b':4,'c':12}\n",
    "params={'steering_parameters':{'m_theta_dist': {'type':'multinomial','parameters':[[0.01 ,0.1, 0.79, 0.1],[0.1, 0.5, 0.8, 1]],'round':False,'decimals':None},\n",
    "                            'del_prob':0.05},'ndtata':['all']}\n",
    "\n",
    "print(params['steering_parameters']['m_theta_dist']['parameters'][1])\n",
    "\n",
    "\n",
    "def printdata(ndata):\n",
    "    if ndata == ['all']:\n",
    "        ndata = list(data.keys())\n",
    "\n",
    "    if ndata[0] == 'allexcept':\n",
    "        ndata = list(data.keys() - ndata[1])\n",
    "    print(ndata)\n",
    "\n",
    "\n",
    "printdata(['all'])\n",
    "printdata(['allexcept',['a']])\n",
    "printdata(['allexcept',['a','c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': tensor([0.7603, 0.7641, 0.9275, 0.7906, 0.7858, 0.7832, 0.3904, 0.3924, 0.7884]), 'sigma': tensor([1.3000, 1.8000, 0.6000, 0.7000, 1.2000, 1.1000, 0.7000, 1.8000, 1.4000]), 'alpha': tensor([0.9952, 1.1045, 1.0706, 1.0489, 1.0576, 1.1922, 1.0162, 1.0938, 1.1324]), 'wealth': tensor([0.9998, 1.1309, 1.1439, 1.0342, 1.2321, 1.0819, 1.0326, 1.1193, 1.0707]), 'a_table': tensor([[[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.9000],\n",
      "         [0.0000, 0.2500, 0.4500]]]), 'wealth_consumption': tensor([4.4039e-01, 5.6813e-01, 3.5487e-01, 3.7399e-01, 5.1065e-01, 5.0570e-01,\n",
      "        3.3307e-01, 3.5862e-04, 5.3021e-01]), 'i_a': tensor([0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.4500, 0.0000, 0.0000, 0.4500]), 'm': tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.0000, 0.0000, 0.9000])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def income_function(k,,tech): \n",
    "    f= * k**tech['gamma'] - tech['cost']\n",
    "    return torch.max(f)\n",
    "\n",
    "\n",
    "class BellmanEquation:\n",
    "    #Adapted from: https://python.quantecon.org/optgrowth.html\n",
    "    def __init__(self,\n",
    "                u,            # utility function\n",
    "                f,            # production function\n",
    "                k,            # current state k_t\n",
    "                ,            # given shock factor \n",
    "                ,            # risk averseness\n",
    "                ,            # human capital\n",
    "                i_a,          # adaptation investment\n",
    "                m,            # protection multiplier\n",
    "                ,            # discount factor\n",
    "                ,            # depreciation factor \n",
    "                tech):       # adaptation table \n",
    "                #name=\"BellmanNarrowExtended\"\n",
    "                \n",
    "\n",
    "        self.u, self.f, self.k, self., self., self., self., self., self.i_a, self.m, self.tech = u, f, k, , , , , , i_a, m, tech\n",
    "\n",
    "        # Set up grid\n",
    "        \n",
    "        startgrid=np.array([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+100])\n",
    "\n",
    "        ind=np.searchsorted(startgrid, k)\n",
    "        self.grid=np.concatenate((startgrid[:ind],np.array([k*0.99999, k]),\n",
    "                                startgrid[ind:]))\n",
    "\n",
    "        self.grid=self.grid[self.grid>i_a]\n",
    "\n",
    "        # Identify target state k\n",
    "        self.index = np.searchsorted(self.grid, k)-1\n",
    "    def value(self, c, y, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation.\n",
    "        \"\"\"\n",
    "\n",
    "        u, f, , , , , , i_a, m, tech = self.u, self.f, self., self., self., self., self., self.i_a, self.m, self.tech\n",
    "\n",
    "        v = interp1d(self.grid, v_array, bounds_error=False, \n",
    "                    fill_value=\"extrapolate\")\n",
    "        return u(c,) +  * v(( + m * (1-)) * (f(y,,tech) - c - i_a + (1 - ) * y))\n",
    "\n",
    "\n",
    "def _optimized_wealth_consumption(model_graph, model_params):\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    def maximize(g, a, b, args):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example \n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        Maximize the function g over the interval [a, b].\n",
    "\n",
    "        The maximizer of g on any interval is\n",
    "        also the minimizer of -g.  The tuple args collects any extra\n",
    "        arguments to g.\n",
    "\n",
    "        Returns the maximum value and the maximizer.\n",
    "        \"\"\"\n",
    "\n",
    "        objective = lambda x: -g(x, *args)\n",
    "        result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "        maximizer, maximum = result.x, -result.fun\n",
    "        return maximizer, maximum\n",
    "\n",
    "    def utility(c, , type=\"isoelastic\"):\n",
    "        if type == \"isoelastic\":\n",
    "            if  ==1:\n",
    "                return np.log(c)\n",
    "            else:\n",
    "                return (c**(1-)-1)/(1-)\n",
    "\n",
    "        else:\n",
    "            print(\"Unspecified utility function!!!\")\n",
    "\n",
    "\n",
    "    def update_bellman(v, bell):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        The Bellman operator.  Updates the guess of the value function\n",
    "        and also computes a v-greedy policy.\n",
    "\n",
    "        * bell is an instance of Bellman equation\n",
    "        * v is an array representing a guess of the value function\n",
    "\n",
    "        \"\"\"\n",
    "        v_new = np.empty_like(v)\n",
    "        v_greedy = np.empty_like(v)\n",
    "        \n",
    "        for i in range(len(bell.grid)):\n",
    "            y = bell.grid[i]\n",
    "            # Maximize RHS of Bellman equation at state y\n",
    "            \n",
    "            c_star, v_max = maximize(bell.value, min([1e-8,y*0.00001]), \n",
    "                                    y-bell.i_a, (y, v))\n",
    "            #VMG HELP! can anyone check that (1) subtracting i_a and \n",
    "            # (2) omitting any grid values less than i_a \n",
    "            # will not be problematic? The only thing I can come up with\n",
    "            # is if i_a is greater than k*0.99999\n",
    "            # which_bellman() now accounts for that case. Whole thing \n",
    "            # could use refinement.\n",
    "        \n",
    "            v_new[i] = v_max\n",
    "            v_greedy[i] = c_star\n",
    "\n",
    "        return v_greedy, v_new\n",
    "\n",
    "\n",
    "    def which_bellman(agentinfo):\n",
    "        \"\"\"\n",
    "        Solves bellman for each affordable adaptation option.\n",
    "        \"\"\"\n",
    "        feasible=[]\n",
    "\n",
    "        for option in torch.transpose(agentinfo['adapt'],0,1):\n",
    "            if option[1]>=((income_function(agentinfo['k'],agentinfo[''],tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']})+(1 - model_params['depreciation'])*agentinfo['k'])*.99998):\n",
    "                # ensures that the gridpoint\n",
    "                # just below k, k*0.99999, is included\n",
    "                pass\n",
    "            else:\n",
    "                #  print(f'working theta = {agentinfo. + option[0] *\\\n",
    "                #  (1-agentinfo.)}, i_a= {option[1]}, k= {agentinfo.k}')\n",
    "                c,v=solve_bellman(BellmanEquation(u=utility, \n",
    "                                f=income_function, k=agentinfo['k'], \n",
    "                                =agentinfo[''], =agentinfo[''], \n",
    "                                =agentinfo[''], i_a=option[1].numpy(),m=option[0],\n",
    "                                =model_params['discount'], =model_params['depreciation'],\n",
    "                                tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']}))\n",
    "                feasible.append([v,c,option[1],option[0]])\n",
    "\n",
    "        best=min(feasible)\n",
    "\n",
    "        return best[1],best[2],best[3]\n",
    "\n",
    "    def solve_bellman(bell,\n",
    "                    tol=1,\n",
    "                    min_iter=10,\n",
    "                    max_iter=1000,\n",
    "                    verbose=False):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        Solve model by iterating with the Bellman operator.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Set up loop\n",
    "\n",
    "        v = bell.u(bell.grid,bell.)  # Initial condition\n",
    "        i = 0\n",
    "        error = tol + 1\n",
    "\n",
    "        while (i < max_iter and error > tol) or (i < min_iter):\n",
    "            v_greedy, v_new = update_bellman(v, bell)\n",
    "            error = np.abs(v[bell.index] - v_new)[bell.index]\n",
    "            i += 1\n",
    "            # if verbose and i % print_skip == 0:\n",
    "            #     print(f\"Error at iteration {i} is {error}.\")\n",
    "            v = v_new\n",
    "\n",
    "        if error > tol:\n",
    "            print(f\"{bell.name} failed to converge for k={bell.k},  = {bell.}, ={bell.}, i_a={bell.i_a}, and modified  = {bell. + bell.m * (1-bell.)}!\")\n",
    "        elif verbose:\n",
    "            print(f\"Converged in {i} iterations.\")\n",
    "            print(f\"Effective k and new c {np.around(bell.grid[bell.index],3),v_greedy[bell.index]}\")\n",
    "            \n",
    "\n",
    "        return v_greedy[bell.index],v[bell.index]\n",
    "    \n",
    "    model_graph['wealth_consumption'], model_graph['i_a'], model_graph['m'] = torch.zeros(9),torch.zeros(9),torch.zeros(9)\n",
    "    for i in range(model_params['number_agents']):\n",
    "        agentinfo = {'u':utility, 'f':income_function, '':model_params['discount'], '':model_graph['theta'][i], '':model_params['depreciation'], '':model_graph['sigma'][i].numpy(), '': model_graph['alpha'][i],'k':model_graph['wealth'][i],'adapt': model_graph['a_table'][i]}\n",
    "        model_graph['wealth_consumption'][i], model_graph['i_a'][i], model_graph['m'][i] = which_bellman(agentinfo)\n",
    "    print(model_graph)\n",
    "\n",
    "modelpar={'discount':0.95,'depreciation':0.08,'number_agents':9,'tech_gamma': torch.tensor([0.3,0.35,0.45]),'tech_cost': torch.tensor([0,0.15,0.65]),'num_nodes':9}        \n",
    "ndata={'theta':torch.tensor([0.7603, 0.7641, 0.9275, 0.7906, 0.7858, 0.7832, 0.3904, 0.3924, 0.7884]),'sigma':torch.tensor([1.3000, 1.8000, 0.6000, 0.7000, 1.2000, 1.1000, 0.7000, 1.8000, 1.4000]),'alpha':torch.tensor([0.9952, 1.1045, 1.0706, 1.0489, 1.0576, 1.1922, 1.0162, 1.0938, 1.1324]),'wealth':torch.tensor([0.9998, 1.1309, 1.1439, 1.0342, 1.2321, 1.0819, 1.0326, 1.1193, 1.0707]), 'a_table':torch.stack([torch.tensor([0,0.5,0.9]),torch.tensor([0,0.25,0.45])]).repeat(modelpar['number_agents'],1,1)}\n",
    "_optimized_wealth_consumption(ndata,modelpar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "0.3666666775941849 533.3333016633987\n",
      "tensor([3.6667e-01, 5.3333e+02])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class torchInterp1d:\n",
    "    \"\"\"\n",
    "    PyTorch-friendly, 1-D linear interpolation.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "       \n",
    "\n",
    "    def __call__(self, x_target):\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "\n",
    "        y_target = torch.empty_like(x_target)\n",
    "\n",
    "        for i, x_val in enumerate(x_target):\n",
    "            if x_val < x[0]:\n",
    "                x_1,y_1,x_2,y_2 = x[0],y[0],x[1],y[1]\n",
    "                y_base,x_base = y[0], x[0] \n",
    "            elif x_val > x[-1]:\n",
    "                x_1,y_1,x_2,y_2=x[-2],y[-2],x[-1],y[-1]\n",
    "                y_base,x_base = y[-1],x[-1]\n",
    "            else:\n",
    "                ind = torch.searchsorted(x, x_val)\n",
    "                if ind==14:\n",
    "                    print(x)\n",
    "                    print(y)\n",
    "                    print(x_val)\n",
    "                x_1,y_1,x_2,y_2 = x[ind-1],y[ind-1],x[ind],y[ind]\n",
    "                y_base,x_base=y[ind-1],x[ind-1]\n",
    "\n",
    "\n",
    "            y_target[i] = y_base + (x_val - x_base) * (y_2-y_1)/(x_2-x_1)\n",
    "\n",
    "        return y_target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "startgrid=torch.tensor([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+100])\n",
    "\n",
    "ind=torch.searchsorted(startgrid, k)\n",
    "grid=torch.cat((startgrid[:ind],torch.tensor([k*0.99999, k]),\n",
    "                        startgrid[ind:]))\n",
    "\n",
    "\n",
    "\n",
    "v_array =grid/3\n",
    "print(type(v_array))\n",
    "print(type(grid))\n",
    "v = interp1d(grid, v_array, bounds_error=False, \n",
    "            fill_value=\"extrapolate\")\n",
    "print(v(1.1),v(1600))\n",
    "\n",
    "\n",
    "v = torchInterp1d(grid, v_array)\n",
    "print(v(torch.tensor([1.1,1600])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint1\n",
      "checkpoint2\n",
      "Epoch: 01/30 Loss: 9.51646e+03\n",
      "Epoch: 02/30 Loss: 9.51646e+03\n",
      "Epoch: 03/30 Loss: 9.51645e+03\n",
      "Epoch: 04/30 Loss: 9.51645e+03\n",
      "Epoch: 05/30 Loss: 9.51644e+03\n",
      "Epoch: 06/30 Loss: 9.51644e+03\n",
      "Epoch: 07/30 Loss: 9.51643e+03\n",
      "Epoch: 08/30 Loss: 9.51643e+03\n",
      "Epoch: 09/30 Loss: 9.51642e+03\n",
      "Epoch: 10/30 Loss: 9.51642e+03\n",
      "Epoch: 11/30 Loss: 9.51641e+03\n",
      "Epoch: 12/30 Loss: 9.51641e+03\n",
      "Epoch: 13/30 Loss: 9.51640e+03\n",
      "Epoch: 14/30 Loss: 9.51640e+03\n",
      "Epoch: 15/30 Loss: 9.51639e+03\n",
      "Epoch: 16/30 Loss: 9.51639e+03\n",
      "Epoch: 17/30 Loss: 9.51638e+03\n",
      "Epoch: 18/30 Loss: 9.51638e+03\n",
      "Epoch: 19/30 Loss: 9.51637e+03\n",
      "Epoch: 20/30 Loss: 9.51637e+03\n",
      "Epoch: 21/30 Loss: 9.51636e+03\n",
      "Epoch: 22/30 Loss: 9.51636e+03\n",
      "Epoch: 23/30 Loss: 9.51635e+03\n",
      "Epoch: 24/30 Loss: 9.51635e+03\n",
      "Epoch: 25/30 Loss: 9.51634e+03\n",
      "Epoch: 26/30 Loss: 9.51634e+03\n",
      "Epoch: 27/30 Loss: 9.51634e+03\n",
      "Epoch: 28/30 Loss: 9.51633e+03\n",
      "Epoch: 29/30 Loss: 9.51633e+03\n",
      "Epoch: 30/30 Loss: 9.51632e+03\n",
      "tensor([ 1.0000,  0.3333,  0.3333,  0.3333,  0.6667,  1.0000,  1.3333,  1.6667,\n",
      "         2.0000,  2.3333,  2.6667,  3.0000,  3.3333, 33.6666],\n",
      "       requires_grad=True)\n",
      "tensor([ 6.9386e+02,  1.1812e+00,  1.1811e+00,  1.1808e+00, -5.8521e-02,\n",
      "        -7.0947e-01, -1.1444e+00, -1.4487e+00, -1.6993e+00, -1.8937e+00,\n",
      "        -2.0646e+00, -2.2063e+00, -2.3355e+00, -4.1064e+00],\n",
      "       grad_fn=<NegBackward0>)\n",
      "checkpoint3\n",
      "tensor(1.1814, grad_fn=<SelectBackward0>)\n",
      "checkpoint1\n",
      "checkpoint2\n",
      "Epoch: 01/30 Loss: -1.60943e+04\n",
      "Epoch: 02/30 Loss: -1.60944e+04\n",
      "Epoch: 03/30 Loss: -1.60944e+04\n",
      "Epoch: 04/30 Loss: -1.60944e+04\n",
      "Epoch: 05/30 Loss: -1.60944e+04\n",
      "Epoch: 06/30 Loss: -1.60944e+04\n",
      "Epoch: 07/30 Loss: -1.60945e+04\n",
      "Epoch: 08/30 Loss: -1.60945e+04\n",
      "Epoch: 09/30 Loss: -1.60945e+04\n",
      "Epoch: 10/30 Loss: -1.60945e+04\n",
      "Epoch: 11/30 Loss: -1.60945e+04\n",
      "Epoch: 12/30 Loss: -1.60946e+04\n",
      "Epoch: 13/30 Loss: -1.60946e+04\n",
      "Epoch: 14/30 Loss: -1.60946e+04\n",
      "Epoch: 15/30 Loss: -1.60946e+04\n",
      "Epoch: 16/30 Loss: -1.60947e+04\n",
      "Epoch: 17/30 Loss: -1.60947e+04\n",
      "Epoch: 18/30 Loss: -1.60947e+04\n",
      "Epoch: 19/30 Loss: -1.60947e+04\n",
      "Epoch: 20/30 Loss: -1.60947e+04\n",
      "Epoch: 21/30 Loss: -1.60948e+04\n",
      "Epoch: 22/30 Loss: -1.60948e+04\n",
      "Epoch: 23/30 Loss: -1.60948e+04\n",
      "Epoch: 24/30 Loss: -1.60948e+04\n",
      "Epoch: 25/30 Loss: -1.60948e+04\n",
      "Epoch: 26/30 Loss: -1.60949e+04\n",
      "Epoch: 27/30 Loss: -1.60949e+04\n",
      "Epoch: 28/30 Loss: -1.60949e+04\n",
      "Epoch: 29/30 Loss: -1.60949e+04\n",
      "Epoch: 30/30 Loss: -1.60949e+04\n",
      "tensor([ 1.0001,  0.3333,  0.3333,  0.3333,  0.6667,  1.0000,  1.3333,  1.6667,\n",
      "         2.0000,  2.3333,  2.6667,  3.0000,  3.3333, 33.6666],\n",
      "       requires_grad=True)\n",
      "tensor([-1.1557e+03,  4.1831e-01,  4.1831e-01,  4.1819e-01,  2.7910e-01,\n",
      "         2.9688e-01,  3.5574e-01,  3.8901e-01,  4.5263e-01,  4.8453e-01,\n",
      "         5.3156e-01,  5.7222e-01,  6.2205e-01,  7.9656e-01],\n",
      "       grad_fn=<NegBackward0>)\n",
      "checkpoint3\n",
      "tensor(0.7629, grad_fn=<SelectBackward0>)\n",
      "checkpoint1\n",
      "checkpoint2\n",
      "Epoch: 01/30 Loss: 2.68647e+04\n",
      "Epoch: 02/30 Loss: 2.68646e+04\n",
      "Epoch: 03/30 Loss: 2.68646e+04\n",
      "Epoch: 04/30 Loss: 2.68644e+04\n",
      "Epoch: 05/30 Loss: 2.68644e+04\n",
      "Epoch: 06/30 Loss: 2.68643e+04\n",
      "Epoch: 07/30 Loss: 2.68641e+04\n",
      "Epoch: 08/30 Loss: 2.68641e+04\n",
      "Epoch: 09/30 Loss: 2.68640e+04\n",
      "Epoch: 10/30 Loss: 2.68639e+04\n",
      "Epoch: 11/30 Loss: 2.68638e+04\n",
      "Epoch: 12/30 Loss: 2.68637e+04\n",
      "Epoch: 13/30 Loss: 2.68636e+04\n",
      "Epoch: 14/30 Loss: 2.68635e+04\n",
      "Epoch: 15/30 Loss: 2.68634e+04\n",
      "Epoch: 16/30 Loss: 2.68633e+04\n",
      "Epoch: 17/30 Loss: 2.68632e+04\n",
      "Epoch: 18/30 Loss: 2.68631e+04\n",
      "Epoch: 19/30 Loss: 2.68630e+04\n",
      "Epoch: 20/30 Loss: 2.68629e+04\n",
      "Epoch: 21/30 Loss: 2.68628e+04\n",
      "Epoch: 22/30 Loss: 2.68627e+04\n",
      "Epoch: 23/30 Loss: 2.68626e+04\n",
      "Epoch: 24/30 Loss: 2.68625e+04\n",
      "Epoch: 25/30 Loss: 2.68624e+04\n",
      "Epoch: 26/30 Loss: 2.68623e+04\n",
      "Epoch: 27/30 Loss: 2.68622e+04\n",
      "Epoch: 28/30 Loss: 2.68621e+04\n",
      "Epoch: 29/30 Loss: 2.68620e+04\n",
      "Epoch: 30/30 Loss: 2.68619e+04\n",
      "tensor([ 0.9997,  0.3333,  0.3333,  0.3333,  0.6667,  1.0000,  1.3333,  1.6667,\n",
      "         2.0000,  2.3333,  2.6667,  3.0000,  3.3333, 33.6666],\n",
      "       requires_grad=True)\n",
      "tensor([ 1.9263e+03,  9.3107e-01,  9.3106e-01,  9.3080e-01,  1.4270e-01,\n",
      "        -2.7174e-01, -5.5649e-01, -7.8117e-01, -9.6259e-01, -1.1020e+00,\n",
      "        -1.2205e+00, -1.3390e+00, -1.4435e+00, -2.8375e+00],\n",
      "       grad_fn=<NegBackward0>)\n",
      "checkpoint3\n",
      "tensor(0.5128, grad_fn=<SelectBackward0>)\n",
      "checkpoint1\n",
      "checkpoint2\n",
      "Epoch: 01/30 Loss: -4.49244e+04\n",
      "Epoch: 02/30 Loss: -4.49246e+04\n",
      "Epoch: 03/30 Loss: -4.49249e+04\n",
      "Epoch: 04/30 Loss: -4.49251e+04\n",
      "Epoch: 05/30 Loss: -4.49253e+04\n",
      "Epoch: 06/30 Loss: -4.49256e+04\n",
      "Epoch: 07/30 Loss: -4.49258e+04\n",
      "Epoch: 08/30 Loss: -4.49260e+04\n",
      "Epoch: 09/30 Loss: -4.49263e+04\n",
      "Epoch: 10/30 Loss: -4.49265e+04\n",
      "Epoch: 11/30 Loss: -4.49268e+04\n",
      "Epoch: 12/30 Loss: -4.49270e+04\n",
      "Epoch: 13/30 Loss: -4.49273e+04\n",
      "Epoch: 14/30 Loss: -4.49275e+04\n",
      "Epoch: 15/30 Loss: -4.49277e+04\n",
      "Epoch: 16/30 Loss: -4.49279e+04\n",
      "Epoch: 17/30 Loss: -4.49282e+04\n",
      "Epoch: 18/30 Loss: -4.49284e+04\n",
      "Epoch: 19/30 Loss: -4.49286e+04\n",
      "Epoch: 20/30 Loss: -4.49288e+04\n",
      "Epoch: 21/30 Loss: -4.49291e+04\n",
      "Epoch: 22/30 Loss: -4.49293e+04\n",
      "Epoch: 23/30 Loss: -4.49296e+04\n",
      "Epoch: 24/30 Loss: -4.49298e+04\n",
      "Epoch: 25/30 Loss: -4.49300e+04\n",
      "Epoch: 26/30 Loss: -4.49303e+04\n",
      "Epoch: 27/30 Loss: -4.49305e+04\n",
      "Epoch: 28/30 Loss: -4.49308e+04\n",
      "Epoch: 29/30 Loss: -4.49310e+04\n",
      "Epoch: 30/30 Loss: -4.49312e+04\n",
      "tensor([ 1.0004,  0.3333,  0.3333,  0.3333,  0.6667,  1.0000,  1.3333,  1.6667,\n",
      "         2.0000,  2.3333,  2.6667,  3.0000,  3.3333, 33.6666],\n",
      "       requires_grad=True)\n",
      "tensor([-3.2104e+03,  5.6898e-01,  5.6897e-01,  5.6879e-01,  1.6354e-01,\n",
      "         1.8047e-02, -4.4619e-02, -9.1976e-02, -1.0290e-01, -1.1208e-01,\n",
      "        -1.0397e-01, -9.8336e-02, -8.2970e-02, -2.1055e-01],\n",
      "       grad_fn=<NegBackward0>)\n",
      "checkpoint3\n",
      "tensor(0.3621, grad_fn=<SelectBackward0>)\n",
      "checkpoint1\n",
      "checkpoint2\n",
      "Epoch: 01/30 Loss: 7.48624e+04\n",
      "Epoch: 02/30 Loss: 7.48616e+04\n",
      "Epoch: 03/30 Loss: 7.48608e+04\n",
      "Epoch: 04/30 Loss: 7.48601e+04\n",
      "tensor([1.0000e-07, 9.9979e-01, 9.9980e-01, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
      "        4.0000e+00, 5.0000e+00, 6.0000e+00, 7.0000e+00, 8.0000e+00, 9.0000e+00,\n",
      "        1.0000e+01, 1.0100e+02])\n",
      "tensor([-3.2104e+03,  5.6898e-01,  5.6897e-01,  5.6879e-01,  1.6354e-01,\n",
      "         1.8047e-02, -4.4619e-02, -9.1976e-02, -1.0290e-01, -1.1208e-01,\n",
      "        -1.0397e-01, -9.8336e-02, -8.2970e-02, -2.1055e-01],\n",
      "       grad_fn=<NegBackward0>)\n",
      "tensor(nan, grad_fn=<UnbindBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for dimension 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 229\u001b[0m\n\u001b[1;32m    227\u001b[0m modelpar\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdiscount\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.95\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdepreciation\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.08\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mnumber_agents\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m9\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtech_gamma\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.3\u001b[39m,\u001b[39m0.35\u001b[39m,\u001b[39m0.45\u001b[39m]),\u001b[39m'\u001b[39m\u001b[39mtech_cost\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m,\u001b[39m0.15\u001b[39m,\u001b[39m0.65\u001b[39m]),\u001b[39m'\u001b[39m\u001b[39mnum_nodes\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m9\u001b[39m}        \n\u001b[1;32m    228\u001b[0m ndata\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtheta\u001b[39m\u001b[39m'\u001b[39m:torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.7603\u001b[39m, \u001b[39m0.7641\u001b[39m, \u001b[39m0.9275\u001b[39m, \u001b[39m0.7906\u001b[39m, \u001b[39m0.7858\u001b[39m, \u001b[39m0.7832\u001b[39m, \u001b[39m0.3904\u001b[39m, \u001b[39m0.3924\u001b[39m, \u001b[39m0.7884\u001b[39m]),\u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m:torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.3000\u001b[39m, \u001b[39m1.8000\u001b[39m, \u001b[39m0.6000\u001b[39m, \u001b[39m0.7000\u001b[39m, \u001b[39m1.2000\u001b[39m, \u001b[39m1.1000\u001b[39m, \u001b[39m0.7000\u001b[39m, \u001b[39m1.8000\u001b[39m, \u001b[39m1.4000\u001b[39m]),\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m:torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.9952\u001b[39m, \u001b[39m1.1045\u001b[39m, \u001b[39m1.0706\u001b[39m, \u001b[39m1.0489\u001b[39m, \u001b[39m1.0576\u001b[39m, \u001b[39m1.1922\u001b[39m, \u001b[39m1.0162\u001b[39m, \u001b[39m1.0938\u001b[39m, \u001b[39m1.1324\u001b[39m]),\u001b[39m'\u001b[39m\u001b[39mwealth\u001b[39m\u001b[39m'\u001b[39m:torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.9998\u001b[39m, \u001b[39m1.1309\u001b[39m, \u001b[39m1.1439\u001b[39m, \u001b[39m1.0342\u001b[39m, \u001b[39m1.2321\u001b[39m, \u001b[39m1.0819\u001b[39m, \u001b[39m1.0326\u001b[39m, \u001b[39m1.1193\u001b[39m, \u001b[39m1.0707\u001b[39m]), \u001b[39m'\u001b[39m\u001b[39ma_table\u001b[39m\u001b[39m'\u001b[39m:torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m,\u001b[39m0.5\u001b[39m,\u001b[39m0.9\u001b[39m]),torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m,\u001b[39m0.25\u001b[39m,\u001b[39m0.45\u001b[39m])])\u001b[39m.\u001b[39mrepeat(modelpar[\u001b[39m'\u001b[39m\u001b[39mnumber_agents\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)}\n\u001b[0;32m--> 229\u001b[0m _torch_optimized_wealth_consumption(ndata,modelpar)\n",
      "Cell \u001b[0;32mIn[174], line 224\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption\u001b[0;34m(model_graph, model_params)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(model_params[\u001b[39m'\u001b[39m\u001b[39mnumber_agents\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    223\u001b[0m     agentinfo \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m:utility, \u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m:income_function, \u001b[39m'\u001b[39m\u001b[39m\u001b[39m\u001b[39m'\u001b[39m:model_params[\u001b[39m'\u001b[39m\u001b[39mdiscount\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m\u001b[39m\u001b[39m'\u001b[39m:model_graph[\u001b[39m'\u001b[39m\u001b[39mtheta\u001b[39m\u001b[39m'\u001b[39m][i], \u001b[39m'\u001b[39m\u001b[39m\u001b[39m\u001b[39m'\u001b[39m:model_params[\u001b[39m'\u001b[39m\u001b[39mdepreciation\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m\u001b[39m\u001b[39m'\u001b[39m:model_graph[\u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m][i]\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39m\u001b[39m\u001b[39m'\u001b[39m: model_graph[\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m][i],\u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m:model_graph[\u001b[39m'\u001b[39m\u001b[39mwealth\u001b[39m\u001b[39m'\u001b[39m][i],\u001b[39m'\u001b[39m\u001b[39madapt\u001b[39m\u001b[39m'\u001b[39m: model_graph[\u001b[39m'\u001b[39m\u001b[39ma_table\u001b[39m\u001b[39m'\u001b[39m][i]}\n\u001b[0;32m--> 224\u001b[0m     model_graph[\u001b[39m'\u001b[39m\u001b[39mwealth_consumption\u001b[39m\u001b[39m'\u001b[39m][i], model_graph[\u001b[39m'\u001b[39m\u001b[39mi_a\u001b[39m\u001b[39m'\u001b[39m][i], model_graph[\u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m which_bellman(agentinfo)\n\u001b[1;32m    225\u001b[0m \u001b[39mprint\u001b[39m(model_graph)\n",
      "Cell \u001b[0;32mIn[174], line 166\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption.<locals>.which_bellman\u001b[0;34m(agentinfo)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         \u001b[39m#  print(f'working theta = {agentinfo. + option[0] *\\\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39m#  (1-agentinfo.)}, i_a= {option[1]}, k= {agentinfo.k}')\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m         c,v\u001b[39m=\u001b[39msolve_bellman(TensBellmanEquation(u\u001b[39m=\u001b[39;49mutility, \n\u001b[1;32m    167\u001b[0m                         f\u001b[39m=\u001b[39;49mincome_function, k\u001b[39m=\u001b[39;49magentinfo[\u001b[39m'\u001b[39;49m\u001b[39mk\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    168\u001b[0m                         \u001b[39m=\u001b[39;49magentinfo[\u001b[39m'\u001b[39;49m\u001b[39m\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m=\u001b[39;49magentinfo[\u001b[39m'\u001b[39;49m\u001b[39m\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    169\u001b[0m                         \u001b[39m=\u001b[39;49magentinfo[\u001b[39m'\u001b[39;49m\u001b[39m\u001b[39;49m\u001b[39m'\u001b[39;49m], i_a\u001b[39m=\u001b[39;49moption[\u001b[39m1\u001b[39;49m],m\u001b[39m=\u001b[39;49moption[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    170\u001b[0m                         \u001b[39m=\u001b[39;49mmodel_params[\u001b[39m'\u001b[39;49m\u001b[39mdiscount\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m=\u001b[39;49mmodel_params[\u001b[39m'\u001b[39;49m\u001b[39mdepreciation\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m                         tech\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mgamma\u001b[39;49m\u001b[39m'\u001b[39;49m:model_params[\u001b[39m'\u001b[39;49m\u001b[39mtech_gamma\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mcost\u001b[39;49m\u001b[39m'\u001b[39;49m:model_params[\u001b[39m'\u001b[39;49m\u001b[39mtech_cost\u001b[39;49m\u001b[39m'\u001b[39;49m]}))\n\u001b[1;32m    172\u001b[0m         feasible\u001b[39m.\u001b[39mappend([v,c,option[\u001b[39m1\u001b[39m],option[\u001b[39m0\u001b[39m]])\n\u001b[1;32m    174\u001b[0m best\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(feasible)\n",
      "Cell \u001b[0;32mIn[174], line 198\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption.<locals>.solve_bellman\u001b[0;34m(bell, tol, min_iter, max_iter, verbose)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mwhile\u001b[39;00m (i \u001b[39m<\u001b[39m max_iter \u001b[39mand\u001b[39;00m error \u001b[39m>\u001b[39m tol) \u001b[39mor\u001b[39;00m (i \u001b[39m<\u001b[39m min_iter):\n\u001b[1;32m    197\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcheckpoint1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 198\u001b[0m     v_greedy, v_new \u001b[39m=\u001b[39m update_bellman(v, bell)\n\u001b[1;32m    199\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcheckpoint3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    200\u001b[0m     error \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(v[bell\u001b[39m.\u001b[39mindex] \u001b[39m-\u001b[39m v_new)[bell\u001b[39m.\u001b[39mindex]\n",
      "Cell \u001b[0;32mIn[174], line 138\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption.<locals>.update_bellman\u001b[0;34m(v, bell)\u001b[0m\n\u001b[1;32m    133\u001b[0m b\u001b[39m=\u001b[39m(y\u001b[39m-\u001b[39mbell\u001b[39m.\u001b[39mi_a)\n\u001b[1;32m    135\u001b[0m \u001b[39m#pairs = torch.transpose(torch.stack((a,b),0),1,0).tolist()\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m#boundsequence = [tuple(x) for x in pairs]\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m c_star, v_max \u001b[39m=\u001b[39m torchmaximize(bell\u001b[39m.\u001b[39;49mvalue, a, b, (y, v))\n\u001b[1;32m    139\u001b[0m     \u001b[39m#VMG HELP! can anyone check that (1) subtracting i_a and \u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[39m# (2) omitting any grid values less than i_a \u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39m# will not be problematic? The only thing I can come up with\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[39m# is if i_a is greater than k*0.99999\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39m# which_bellman() now accounts for that case. Whole thing \u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# could use refinement.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m v_new \u001b[39m=\u001b[39m v_max\n",
      "Cell \u001b[0;32mIn[174], line 88\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption.<locals>.torchmaximize\u001b[0;34m(g, a, b, args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x):  \u001b[39m# You can adjust the number of optimization steps\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[39m#history.append(g(x,*args))\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     optimizer\u001b[39m.\u001b[39mstep(closure)\n\u001b[0;32m---> 88\u001b[0m     loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     89\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     91\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m30\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m:\u001b[39;00m\u001b[39m.5e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[174], line 68\u001b[0m, in \u001b[0;36m_torch_optimized_wealth_consumption.<locals>.torchmaximize.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 68\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mg(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     69\u001b[0m     loss\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(value)\n\u001b[1;32m     70\u001b[0m     loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[174], line 44\u001b[0m, in \u001b[0;36mTensBellmanEquation.value\u001b[0;34m(self, c, y, v_array)\u001b[0m\n\u001b[1;32m     40\u001b[0m u, f, , , , , , i_a, m, tech \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mi_a, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtech\n\u001b[1;32m     42\u001b[0m v \u001b[39m=\u001b[39m torchInterp1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid, v_array)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mreturn\u001b[39;00m u(c,) \u001b[39m+\u001b[39m  \u001b[39m*\u001b[39m v(( \u001b[39m+\u001b[39;49m m \u001b[39m*\u001b[39;49m (\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49m)) \u001b[39m*\u001b[39;49m (f(y,,tech) \u001b[39m-\u001b[39;49m c \u001b[39m-\u001b[39;49m i_a \u001b[39m+\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m ) \u001b[39m*\u001b[39;49m y))\n",
      "Cell \u001b[0;32mIn[162], line 29\u001b[0m, in \u001b[0;36mtorchInterp1d.__call__\u001b[0;34m(self, x_target)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[39mprint\u001b[39m(y)\n\u001b[1;32m     28\u001b[0m         \u001b[39mprint\u001b[39m(x_val)\n\u001b[0;32m---> 29\u001b[0m     x_1,y_1,x_2,y_2 \u001b[39m=\u001b[39m x[ind\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],y[ind\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],x[ind],y[ind]\n\u001b[1;32m     30\u001b[0m     y_base,x_base\u001b[39m=\u001b[39my[ind\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],x[ind\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m y_target[i] \u001b[39m=\u001b[39m y_base \u001b[39m+\u001b[39m (x_val \u001b[39m-\u001b[39m x_base) \u001b[39m*\u001b[39m (y_2\u001b[39m-\u001b[39my_1)\u001b[39m/\u001b[39m(x_2\u001b[39m-\u001b[39mx_1)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 14 is out of bounds for dimension 0 with size 14"
     ]
    }
   ],
   "source": [
    "\n",
    "def income_function(k,,tech): \n",
    "    f= * k.unsqueeze(-1)**tech['gamma'] - tech['cost']\n",
    "    return torch.max(f,-1)[0]\n",
    "\n",
    "class TensBellmanEquation:\n",
    "    #Adapted from: https://python.quantecon.org/optgrowth.html\n",
    "    def __init__(self,\n",
    "                u,            # utility function\n",
    "                f,            # production function\n",
    "                k,            # current state k_t\n",
    "                ,            # given shock factor \n",
    "                ,            # risk averseness\n",
    "                ,            # human capital\n",
    "                i_a,          # adaptation investment\n",
    "                m,            # protection multiplier\n",
    "                ,            # discount factor\n",
    "                ,            # depreciation factor \n",
    "                tech):       # adaptation table \n",
    "                #name=\"BellmanNarrowExtended\"\n",
    "                \n",
    "\n",
    "        self.u, self.f, self.k, self., self., self., self., self., self.i_a, self.m, self.tech = u, f, k, , , , , , i_a, m, tech\n",
    "\n",
    "        # Set up grid\n",
    "        \n",
    "        startgrid=torch.tensor([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+100])\n",
    "\n",
    "        ind=torch.searchsorted(startgrid, k)\n",
    "        self.grid=torch.cat((startgrid[:ind],torch.tensor([k*0.99999, k]),\n",
    "                                startgrid[ind:]))\n",
    "\n",
    "        self.grid=self.grid[self.grid>i_a]\n",
    "        # Identify target state k\n",
    "        self.index = torch.searchsorted(self.grid, k)-1\n",
    "    def value(self, c, y, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation.\n",
    "        \"\"\"\n",
    "\n",
    "        u, f, , , , , , i_a, m, tech = self.u, self.f, self., self., self., self., self., self.i_a, self.m, self.tech\n",
    "\n",
    "        v = torchInterp1d(self.grid, v_array)\n",
    "\n",
    "        return u(c,) +  * v(( + m * (1-)) * (f(y,,tech) - c - i_a + (1 - ) * y))\n",
    "\n",
    "\n",
    "\n",
    "def _torch_optimized_wealth_consumption(model_graph, model_params):\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def torchmaximize(g, a, b, args):\n",
    "        \"\"\"\n",
    "        Maximize the function g over the interval [a, b] using PyTorch's LBFGS optimizer.\n",
    "\n",
    "        The tuple args collects any extra arguments to g.\n",
    "\n",
    "        Returns the maximal value and the maximizer.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a closure function  to reset gradient, determine value, and calculate new gradient\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            value = -g(x, *args)\n",
    "            loss= torch.sum(value)\n",
    "            loss.backward(retain_graph=True)\n",
    "            return loss\n",
    "\n",
    "        # Initial guess for consumption\n",
    "        x = (args[0]/3).clone().requires_grad_(True)\n",
    "\n",
    "        # Feed it to optimizer and keep x guesses in the bounds\n",
    "        optimizer = torch.optim.LBFGS([x], history_size=10, max_iter=4)\n",
    "        x.data = torch.clamp(x, a, b)\n",
    "\n",
    "        #history=[]\n",
    "        # Run optimization for 30 epochs:\n",
    "        for epoch in range(30):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, c in enumerate(x):  # You can adjust the number of optimization steps\n",
    "                #history.append(g(x,*args))\n",
    "                optimizer.step(closure)\n",
    "                loss = closure()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch: {epoch + 1:02}/{30} Loss: {running_loss:.5e}\")\n",
    "\n",
    "\n",
    "\n",
    "        maximizer = x\n",
    "        maximum = -g(x, *args)\n",
    "        print(maximizer)\n",
    "        print(maximum)\n",
    "        #print(history)\n",
    "        return maximizer, maximum\n",
    "\n",
    "    def utility(c, , type=\"isoelastic\"):\n",
    "        if type == \"isoelastic\":\n",
    "            if  ==1:\n",
    "                return torch.log(c)\n",
    "            else:\n",
    "                return (c**(1-)-1)/(1-)\n",
    "\n",
    "        else:\n",
    "            print(\"Unspecified utility function!!!\")\n",
    "\n",
    "\n",
    "    def update_bellman(v, bell):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        The Bellman operator.  Updates the guess of the value function\n",
    "        and also computes a v-greedy policy.\n",
    "\n",
    "        * bell is an instance of Bellman equation\n",
    "        * v is an array representing a guess of the value function\n",
    "\n",
    "        \"\"\"\n",
    "        v_new = torch.empty_like(v)\n",
    "        v_greedy = torch.empty_like(v)\n",
    "        \n",
    "        print('checkpoint2')\n",
    "\n",
    "        y = bell.grid\n",
    "        # Maximize RHS of Bellman equation at state y\n",
    "        a=torch.min(torch.transpose(torch.stack((torch.full(y.size(),1e-8),(y*0.00001)),0),0,1),1)[0]\n",
    "        b=(y-bell.i_a)\n",
    "\n",
    "        #pairs = torch.transpose(torch.stack((a,b),0),1,0).tolist()\n",
    "        #boundsequence = [tuple(x) for x in pairs]\n",
    "\n",
    "        c_star, v_max = torchmaximize(bell.value, a, b, (y, v))\n",
    "            #VMG HELP! can anyone check that (1) subtracting i_a and \n",
    "            # (2) omitting any grid values less than i_a \n",
    "            # will not be problematic? The only thing I can come up with\n",
    "            # is if i_a is greater than k*0.99999\n",
    "            # which_bellman() now accounts for that case. Whole thing \n",
    "            # could use refinement.\n",
    "\n",
    "        v_new = v_max\n",
    "        v_greedy = c_star\n",
    "\n",
    "        return v_greedy, v_new\n",
    "\n",
    "\n",
    "    def which_bellman(agentinfo):\n",
    "        \"\"\"\n",
    "        Solves bellman for each affordable adaptation option.\n",
    "        \"\"\"\n",
    "        feasible=[]\n",
    "\n",
    "        for option in torch.transpose(agentinfo['adapt'],0,1):\n",
    "            if option[1]>=(income_function(agentinfo['k'],agentinfo[''],tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']})+(1 - model_params['depreciation'])*agentinfo['k'])*.99998:\n",
    "                # ensures that the gridpoint\n",
    "                # just below k, k*0.99999, is included\n",
    "                pass\n",
    "            else:\n",
    "                #  print(f'working theta = {agentinfo. + option[0] *\\\n",
    "                #  (1-agentinfo.)}, i_a= {option[1]}, k= {agentinfo.k}')\n",
    "                c,v=solve_bellman(TensBellmanEquation(u=utility, \n",
    "                                f=income_function, k=agentinfo['k'], \n",
    "                                =agentinfo[''], =agentinfo[''], \n",
    "                                =agentinfo[''], i_a=option[1],m=option[0],\n",
    "                                =model_params['discount'], =model_params['depreciation'],\n",
    "                                tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']}))\n",
    "                feasible.append([v,c,option[1],option[0]])\n",
    "\n",
    "        best=min(feasible)\n",
    "\n",
    "        return best[1],best[2],best[3]\n",
    "\n",
    "    def solve_bellman(bell,\n",
    "                    tol=1,\n",
    "                    min_iter=10,\n",
    "                    max_iter=1000,\n",
    "                    verbose=False):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        Solve model by iterating with the Bellman operator.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up loop\n",
    "\n",
    "        v = bell.u(bell.grid,bell.)  # Initial condition\n",
    "        i = 0\n",
    "        error = tol + 1\n",
    "        while (i < max_iter and error > tol) or (i < min_iter):\n",
    "            print('checkpoint1')\n",
    "            v_greedy, v_new = update_bellman(v, bell)\n",
    "            print('checkpoint3')\n",
    "            error = torch.abs(v[bell.index] - v_new)[bell.index]\n",
    "            print(error)\n",
    "            i += 1\n",
    "            # if verbose and i % print_skip == 0:\n",
    "            #     print(f\"Error at iteration {i} is {error}.\")\n",
    "            v = v_new\n",
    "\n",
    "        print('checkpoint4')\n",
    "\n",
    "        if error > tol:\n",
    "            print(f\"{bell.name} failed to converge for k={bell.k},  = {bell.}, ={bell.}, i_a={bell.i_a}, and modified  = {bell. + bell.m * (1-bell.)}!\")\n",
    "        elif verbose:\n",
    "            print(f\"Converged in {i} iterations.\")\n",
    "            print(f\"Effective k and new c {torch.round(bell.grid[bell.index],3),v_greedy[bell.index]}\")\n",
    "            \n",
    "\n",
    "        return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    model_graph['wealth_consumption'], model_graph['i_a'], model_graph['m'] = torch.zeros(9),torch.zeros(9),torch.zeros(9)\n",
    "    for i in range(model_params['number_agents']):\n",
    "        agentinfo = {'u':utility, 'f':income_function, '':model_params['discount'], '':model_graph['theta'][i], '':model_params['depreciation'], '':model_graph['sigma'][i].numpy(), '': model_graph['alpha'][i],'k':model_graph['wealth'][i],'adapt': model_graph['a_table'][i]}\n",
    "        model_graph['wealth_consumption'][i], model_graph['i_a'][i], model_graph['m'][i] = which_bellman(agentinfo)\n",
    "    print(model_graph)\n",
    "\n",
    "modelpar={'discount':0.95,'depreciation':0.08,'number_agents':9,'tech_gamma': torch.tensor([0.3,0.35,0.45]),'tech_cost': torch.tensor([0,0.15,0.65]),'num_nodes':9}        \n",
    "ndata={'theta':torch.tensor([0.7603, 0.7641, 0.9275, 0.7906, 0.7858, 0.7832, 0.3904, 0.3924, 0.7884]),'sigma':torch.tensor([1.3000, 1.8000, 0.6000, 0.7000, 1.2000, 1.1000, 0.7000, 1.8000, 1.4000]),'alpha':torch.tensor([0.9952, 1.1045, 1.0706, 1.0489, 1.0576, 1.1922, 1.0162, 1.0938, 1.1324]),'wealth':torch.tensor([0.9998, 1.1309, 1.1439, 1.0342, 1.2321, 1.0819, 1.0326, 1.1193, 1.0707]), 'a_table':torch.stack([torch.tensor([0,0.5,0.9]),torch.tensor([0,0.25,0.45])]).repeat(modelpar['number_agents'],1,1)}\n",
    "_torch_optimized_wealth_consumption(ndata,modelpar)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0079, 7.2906])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base=torch.tensor([1.0000e-07, 1.0100e+02])\n",
    "coef=torch.tensor(0.9952)\n",
    "powers=torch.tensor([0.3000, 0.3500, 0.4500])\n",
    "cost=torch.tensor([0,0.15,0.65])\n",
    "#powers=torch.transpose(powers,-1,0)#.repeat(4,1)\n",
    "print(powers.dtype)\n",
    "print(base.dtype)\n",
    "print(coef.dtype)\n",
    "r1=coef * base[:, None] ** powers - cost\n",
    "torch.max(r1,-1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def income_function(k,,tech): \n",
    "    f= * k.unsqueeze(-1)**tech['gamma'] - tech['cost']\n",
    "    return torch.max(f,-1)[0]\n",
    "\n",
    "class TensBellmanEquation:\n",
    "    #Adapted from: https://python.quantecon.org/optgrowth.html\n",
    "    def __init__(self,\n",
    "                u,            # utility function\n",
    "                f,            # production function\n",
    "                k,            # current state k_t\n",
    "                ,            # given shock factor \n",
    "                ,            # risk averseness\n",
    "                ,            # human capital\n",
    "                i_a,          # adaptation investment\n",
    "                m,            # protection multiplier\n",
    "                ,            # discount factor\n",
    "                ,            # depreciation factor \n",
    "                tech):       # adaptation table \n",
    "                #name=\"BellmanNarrowExtended\"\n",
    "                \n",
    "\n",
    "        self.u, self.f, self.k, self., self., self., self., self., self.i_a, self.m, self.tech = u, f, k, , , , , , i_a, m, tech\n",
    "\n",
    "        # Set up grid\n",
    "        \n",
    "        startgrid=torch.tensor([1.0e-7,1,2,3,4,5,6,7,8,9,10,k+100])\n",
    "\n",
    "        ind=torch.searchsorted(startgrid, k)\n",
    "        self.grid=torch.cat((startgrid[:ind],torch.tensor([k*0.99999, k]),\n",
    "                                startgrid[ind:]))\n",
    "\n",
    "        self.grid=self.grid[self.grid>i_a]\n",
    "        # Identify target state k\n",
    "        self.index = torch.searchsorted(self.grid, k)-1\n",
    "    def value(self, c, y, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation.\n",
    "        \"\"\"\n",
    "\n",
    "        u, f, , , , , , i_a, m, tech = self.u, self.f, self., self., self., self., self., self.i_a, self.m, self.tech\n",
    "\n",
    "        v = torchInterp1d(self.grid, v_array)\n",
    "\n",
    "        return u(c,) +  * v(( + m * (1-)) * (f(y,,tech) - c - i_a + (1 - ) * y))\n",
    "\n",
    "\n",
    "\n",
    "def _torch_optimized_wealth_consumption(model_graph, model_params):\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def torchmaximize(g, a, b, args):\n",
    "        \"\"\"\n",
    "        Maximize the function g over the interval [a, b] using PyTorch's LBFGS optimizer.\n",
    "\n",
    "        The tuple args collects any extra arguments to g.\n",
    "\n",
    "        Returns the maximal value and the maximizer.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a closure function  to reset gradient, determine value, and calculate new gradient\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            value = -g(x, *args)\n",
    "            loss= torch.sum(value)\n",
    "            loss.backward(retain_graph=True)\n",
    "            return loss\n",
    "\n",
    "        # Initial guess for consumption\n",
    "        x = (args[0]/3).clone().requires_grad_(True)\n",
    "\n",
    "        # Feed it to optimizer and keep x guesses in the bounds\n",
    "        optimizer = torch.optim.LBFGS([x], history_size=10, max_iter=4)\n",
    "        x.data = torch.clamp(x, a, b)\n",
    "\n",
    "        #history=[]\n",
    "        # Run optimization for 30 epochs:\n",
    "        for epoch in range(30):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, c in enumerate(x):  # You can adjust the number of optimization steps\n",
    "                #history.append(g(x,*args))\n",
    "                optimizer.step(closure)\n",
    "                loss = closure()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch: {epoch + 1:02}/{30} Loss: {running_loss:.5e}\")\n",
    "\n",
    "\n",
    "\n",
    "        maximizer = x\n",
    "        maximum = -g(x, *args)\n",
    "        print(maximizer)\n",
    "        print(maximum)\n",
    "        #print(history)\n",
    "        return maximizer, maximum\n",
    "\n",
    "    def utility(c, , type=\"isoelastic\"):\n",
    "        if type == \"isoelastic\":\n",
    "            if  ==1:\n",
    "                return torch.log(c)\n",
    "            else:\n",
    "                return (c**(1-)-1)/(1-)\n",
    "\n",
    "        else:\n",
    "            print(\"Unspecified utility function!!!\")\n",
    "\n",
    "\n",
    "    def update_bellman(v, bell):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        The Bellman operator.  Updates the guess of the value function\n",
    "        and also computes a v-greedy policy.\n",
    "\n",
    "        * bell is an instance of Bellman equation\n",
    "        * v is an array representing a guess of the value function\n",
    "\n",
    "        \"\"\"\n",
    "        v_new = torch.empty_like(v)\n",
    "        v_greedy = torch.empty_like(v)\n",
    "        \n",
    "        print('checkpoint2')\n",
    "\n",
    "        y = bell.grid\n",
    "        # Maximize RHS of Bellman equation at state y\n",
    "        a=torch.min(torch.transpose(torch.stack((torch.full(y.size(),1e-8),(y*0.00001)),0),0,1),1)[0]\n",
    "        b=(y-bell.i_a)\n",
    "\n",
    "        #pairs = torch.transpose(torch.stack((a,b),0),1,0).tolist()\n",
    "        #boundsequence = [tuple(x) for x in pairs]\n",
    "\n",
    "        c_star, v_max = torchmaximize(bell.value, a, b, (y, v))\n",
    "            #VMG HELP! can anyone check that (1) subtracting i_a and \n",
    "            # (2) omitting any grid values less than i_a \n",
    "            # will not be problematic? The only thing I can come up with\n",
    "            # is if i_a is greater than k*0.99999\n",
    "            # which_bellman() now accounts for that case. Whole thing \n",
    "            # could use refinement.\n",
    "\n",
    "        v_new = v_max\n",
    "        v_greedy = c_star\n",
    "\n",
    "        return v_greedy, v_new\n",
    "\n",
    "\n",
    "    def which_bellman(agentinfo):\n",
    "        \"\"\"\n",
    "        Solves bellman for each affordable adaptation option.\n",
    "        \"\"\"\n",
    "        feasible=[]\n",
    "\n",
    "        for option in torch.transpose(agentinfo['adapt'],0,1):\n",
    "            if option[1]>=(income_function(agentinfo['k'],agentinfo[''],tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']})+(1 - model_params['depreciation'])*agentinfo['k'])*.99998:\n",
    "                # ensures that the gridpoint\n",
    "                # just below k, k*0.99999, is included\n",
    "                pass\n",
    "            else:\n",
    "                #  print(f'working theta = {agentinfo. + option[0] *\\\n",
    "                #  (1-agentinfo.)}, i_a= {option[1]}, k= {agentinfo.k}')\n",
    "                c,v=solve_bellman(TensBellmanEquation(u=utility, \n",
    "                                f=income_function, k=agentinfo['k'], \n",
    "                                =agentinfo[''], =agentinfo[''], \n",
    "                                =agentinfo[''], i_a=option[1],m=option[0],\n",
    "                                =model_params['discount'], =model_params['depreciation'],\n",
    "                                tech={'gamma':model_params['tech_gamma'],'cost':model_params['tech_cost']}))\n",
    "                feasible.append([v,c,option[1],option[0]])\n",
    "\n",
    "        best=min(feasible)\n",
    "\n",
    "        return best[1],best[2],best[3]\n",
    "\n",
    "    def solve_bellman(bell,\n",
    "                    tol=1,\n",
    "                    min_iter=10,\n",
    "                    max_iter=1000,\n",
    "                    verbose=False):\n",
    "        \"\"\"\n",
    "        From: https://python.quantecon.org/optgrowth.html (similar example\n",
    "        https://macroeconomics.github.io/Dynamic%20Programming.html#.ZC13-exBy3I)\n",
    "        \n",
    "        Solve model by iterating with the Bellman operator.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up loop\n",
    "\n",
    "        v = bell.u(bell.grid,bell.)  # Initial condition\n",
    "        i = 0\n",
    "        error = tol + 1\n",
    "        while (i < max_iter and error > tol) or (i < min_iter):\n",
    "            print('checkpoint1')\n",
    "            v_greedy, v_new = update_bellman(v, bell)\n",
    "            print('checkpoint3')\n",
    "            error = torch.abs(v[bell.index] - v_new)[bell.index]\n",
    "            print(error)\n",
    "            i += 1\n",
    "            # if verbose and i % print_skip == 0:\n",
    "            #     print(f\"Error at iteration {i} is {error}.\")\n",
    "            v = v_new\n",
    "\n",
    "        print('checkpoint4')\n",
    "\n",
    "        if error > tol:\n",
    "            print(f\"{bell.name} failed to converge for k={bell.k},  = {bell.}, ={bell.}, i_a={bell.i_a}, and modified  = {bell. + bell.m * (1-bell.)}!\")\n",
    "        elif verbose:\n",
    "            print(f\"Converged in {i} iterations.\")\n",
    "            print(f\"Effective k and new c {torch.round(bell.grid[bell.index],3),v_greedy[bell.index]}\")\n",
    "            \n",
    "\n",
    "        return v_greedy[bell.index],v[bell.index]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    model_graph['wealth_consumption'], model_graph['i_a'], model_graph['m'] = torch.zeros(9),torch.zeros(9),torch.zeros(9)\n",
    "    for i in range(model_params['number_agents']):\n",
    "        agentinfo = {'u':utility, 'f':income_function, '':model_params['discount'], '':model_graph['theta'][i], '':model_params['depreciation'], '':model_graph['sigma'][i].numpy(), '': model_graph['alpha'][i],'k':model_graph['wealth'][i],'adapt': model_graph['a_table'][i]}\n",
    "        model_graph['wealth_consumption'][i], model_graph['i_a'][i], model_graph['m'][i] = which_bellman(agentinfo)\n",
    "    print(model_graph)\n",
    "\n",
    "modelpar={'discount':0.95,'depreciation':0.08,'number_agents':9,'tech_gamma': torch.tensor([0.3,0.35,0.45]),'tech_cost': torch.tensor([0,0.15,0.65]),'num_nodes':9}        \n",
    "ndata={'theta':torch.tensor([0.7603, 0.7641, 0.9275, 0.7906, 0.7858, 0.7832, 0.3904, 0.3924, 0.7884]),'sigma':torch.tensor([1.3000, 1.8000, 0.6000, 0.7000, 1.2000, 1.1000, 0.7000, 1.8000, 1.4000]),'alpha':torch.tensor([0.9952, 1.1045, 1.0706, 1.0489, 1.0576, 1.1922, 1.0162, 1.0938, 1.1324]),'wealth':torch.tensor([0.9998, 1.1309, 1.1439, 1.0342, 1.2321, 1.0819, 1.0326, 1.1193, 1.0707]), 'a_table':torch.stack([torch.tensor([0,0.5,0.9]),torch.tensor([0,0.25,0.45])]).repeat(modelpar['number_agents'],1,1)}\n",
    "_torch_optimized_wealth_consumption(ndata,modelpar)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('dgl_ptm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1477468427ea6fe7f3c6460347a373a01cc68daae53faf91f7d9fb578ee805b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
